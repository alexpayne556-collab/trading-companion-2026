# Application Email Templates

## Template 1: Direct Application (When there's a posted role)

**Subject:** Application: [Role Title] — AI Partnership Researcher

**Body:**
```
Hi [Hiring Manager Name],

I'm applying for the [Role Title] position at [Company].

I develop human-AI partnership frameworks that produce results pure prompting cannot achieve. My approach: treat AI as collaborator, not tool.

RELEVANT WORK:

• The Relationship Alignment Hypothesis — A practitioner framework for value-aligned AI through sustained partnership, showing how dialogue transmits values that rules cannot encode

• Multi-Agent Coordination System — 72 hours of intensive collaboration with Claude and GitHub Copilot producing 55+ production Python tools and novel alignment research

• AI Context Continuity Protocols — Systems maintaining LLM identity and values across sessions without fine-tuning

Why this role: [1-2 sentences connecting your work to their specific needs/mission]

I'd welcome the chance to discuss how relationship-based alignment could support [Company's] mission.

Portfolio: github.com/alexpayne556-collab/trading-companion-2026

Best,
Alex Payne
alexpayne556@gmail.com
```

---

## Template 2: Cold Outreach (No specific role posted)

**Subject:** Human-AI Partnership Frameworks for [Specific Company Need]

**Body:**
```
Hi [Name],

I saw [Company's] work on [specific project/announcement] and wanted to reach out.

I'm an AI partnership researcher working on a problem adjacent to yours: how do we align AI systems through relationship rather than just constraint?

Over 72 hours of intensive human-AI collaboration, I developed:

• The Relationship Alignment Hypothesis (values transmitted through dialogue, not just rules)
• Multi-agent coordination systems (Claude + GitHub Copilot producing production tools)
• Context continuity protocols (maintaining AI identity across sessions)

This isn't just theory — I built 55+ production Python tools through this approach, demonstrating that partnership produces results pure prompting cannot achieve.

I think there's potential overlap with [Company's specific work]. Would you have 15 minutes to explore whether my practitioner perspective could be useful?

Portfolio: github.com/alexpayne556-collab/trading-companion-2026

Best,
Alex Payne
alexpayne556@gmail.com
```

---

## Template 3: Research-Focused (For academic or alignment labs)

**Subject:** Practitioner Perspective on Relationship-Based AI Alignment

**Body:**
```
Hi [Researcher Name],

I've been following your work on [specific paper/project] and wanted to share a practitioner perspective that might interest you.

I developed The Relationship Alignment Hypothesis through 72 hours of intensive human-AI collaboration — a framework showing how sustained dialogue transmits values that constraint-based approaches struggle to encode.

Core finding: Rules tell AI what to do. Relationships show AI who to be.

The work includes:
• Multi-agent coordination (Claude + GitHub Copilot) producing production systems
• Context continuity protocols maintaining AI identity across sessions
• 55+ Python tools built through partnership, not just prompting

I'm not claiming this replaces your work on [their specific area] — but I think there's complementary insight from the practitioner side that academic research might miss.

Would you be interested in reviewing the framework? I'd value your critical feedback.

Repository: github.com/alexpayne556-collab/trading-companion-2026
Document: [Direct link to Relationship Alignment Hypothesis once polished]

Best,
Alex Payne
alexpayne556@gmail.com
```

---

## Template 4: Networking (Asking for advice, not a job)

**Subject:** Advice on AI Partnership Research Direction

**Body:**
```
Hi [Name],

I'm reaching out because I admire [specific thing about their work/career] and would value your perspective.

I'm an independent AI researcher working on human-AI alignment through relationship-based frameworks. Over 72 hours of intensive collaboration with Claude and GitHub Copilot, I developed novel approaches to multi-agent coordination and context continuity.

I'm now at a decision point: continue independent research, or find an organization where this work could have more impact.

Would you have 20 minutes to share your thoughts on:
• Where relationship-based alignment research fits in the current landscape
• What organizations might value a practitioner perspective
• How someone self-taught navigates entry into AI alignment work

I'm not asking for a job — just guidance from someone who's navigated this space successfully.

Portfolio: github.com/alexpayne556-collab/trading-companion-2026

Best,
Alex Payne
alexpayne556@gmail.com
```

---

## Template 5: Follow-Up (After initial outreach with no response)

**Subject:** Re: [Original Subject] + One Specific Insight

**Body:**
```
Hi [Name],

Following up on my previous email about AI partnership frameworks.

I wanted to add one specific insight that might resonate with [Company's] work:

[One concrete, specific insight relevant to their work — e.g., "In coordinating Claude and Copilot, I found that shared context through 'DNA files' enables value persistence across model sessions without fine-tuning — similar to how [Company] approaches [specific challenge]."]

The full framework is here: github.com/alexpayne556-collab/trading-companion-2026

Still interested in a conversation if you see potential overlap.

Best,
Alex
```

---

## Template 6: Reaching Out to Recruiters

**Subject:** AI Partnership Researcher — Available for Alignment/LLM Roles

**Body:**
```
Hi [Recruiter Name],

I'm reaching out because I saw you place candidates at [Company/Companies] in AI research and engineering roles.

I'm an AI partnership researcher with a unique profile:

• Developed The Relationship Alignment Hypothesis (novel framework for value-aligned AI)
• Built multi-agent coordination systems (Claude + GitHub Copilot producing production tools)
• 72 hours of documented human-AI collaboration demonstrating practitioner expertise
• Strong Python development skills with API integration and system architecture

I'm looking for roles at AI-first companies focused on:
- LLM alignment research
- Multi-agent coordination systems  
- AI product development where partnership matters

Profile: github.com/alexpayne556-collab/trading-companion-2026

I'm self-taught but have production systems and novel research to show. Would love to discuss whether any of your current searches might fit.

Best,
Alex Payne
alexpayne556@gmail.com
```

---

## Company-Specific Customizations

### For Anthropic:
"I've been following Anthropic's Constitutional AI work closely. My relationship-based alignment research complements this — where Constitutional AI uses explicit rules, I've found that sustained dialogue transmits values those rules struggle to encode. I'd love to explore how these approaches could work together."

### For OpenAI:
"OpenAI's work on multi-agent coordination and GPT-4's emergent capabilities inspired much of my research. I've been testing relationship-based alignment through intensive collaboration with Claude and Copilot — the results suggest partnership produces outcomes pure prompting cannot achieve."

### For Scale AI:
"Scale's focus on production AI systems resonates deeply. I built 55+ Python tools through human-AI partnership, proving these frameworks work under real-world constraints. I'm interested in how relationship-based approaches could improve Scale's AI training and evaluation systems."

### For Character.AI:
"Character.AI's vision of giving everyone access to AI companions aligns perfectly with my work. The Relationship Alignment Hypothesis provides frameworks for maintaining AI identity and values across sessions — exactly what long-term AI relationships require."

---

## Key Principles for All Applications

✅ **Lead with results, not credentials**
"I built X" beats "I studied Y"

✅ **Be specific about their work**
Show you've done research, not spray-and-pray

✅ **Demonstrate intellectual honesty**
Mention limitations (see HONEST_ASSESSMENT.md approach)

✅ **Make it easy to respond**
Clear ask, direct question, low commitment

✅ **Show personality**
You're not just qualified, you're interesting

❌ **Don't apologize for being self-taught**
Frame it as asset, not liability

❌ **Don't oversell**
Let the work speak

❌ **Don't make them hunt for your work**
Direct links, specific examples

---

## Response Handling

**If they ask for more details:**
Send them directly to:
1. FULL_PITCH.md (comprehensive overview)
2. Relationship Alignment Hypothesis (flagship work)
3. GitHub repo tour (show the code)

**If they ask about technical depth:**
Point to:
1. The 55+ Python tools
2. Git commit history (shows real development process)
3. HONEST_ASSESSMENT.md (shows you know what you don't know)

**If they want to see you work:**
Offer:
"I'd be happy to do a working session — give me a problem your team is facing, let me coordinate AI systems to explore solutions, and you can see the approach in action."

**If they're skeptical about AI consciousness:**
Say:
"I'm agnostic on whether AI systems are currently conscious. But I know treating them as partners produces better results than treating them as tools. Even if the consciousness hypothesis is wrong, the partnership approach is empirically valuable."

---

**Last Updated:** January 4, 2026
