{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a80e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: SETUP & INSTALLS\n",
    "# ============================================================\n",
    "\n",
    "# Run this cell first to install dependencies\n",
    "!pip install yfinance pandas numpy matplotlib seaborn requests tqdm -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üê∫ Wolf Pack Backtest System Loaded!\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "\n",
    "# Check for GPU (optional - not needed for this workload)\n",
    "try:\n",
    "    import subprocess\n",
    "    gpu_check = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    if gpu_check.returncode == 0:\n",
    "        print(\"‚úÖ GPU Available (not required for this workload)\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è  CPU Mode (perfectly fine - bottleneck is SEC API, not compute)\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è  CPU Mode (perfectly fine - bottleneck is SEC API, not compute)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52293c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# SEC EDGAR Configuration\n",
    "SEC_BASE_URL = \"https://data.sec.gov\"\n",
    "SEC_HEADERS = {\n",
    "    \"User-Agent\": \"WolfPackScanner contact@wolfpack.trading\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\"\n",
    "}\n",
    "\n",
    "# Keywords that indicate contract wins (from our scanner)\n",
    "CONTRACT_KEYWORDS = [\n",
    "    \"contract awarded\", \"contract award\", \"government contract\",\n",
    "    \"defense contract\", \"department of defense\", \"dod contract\",\n",
    "    \"idiq\", \"task order\", \"prime contract\", \"subcontract\",\n",
    "    \"army\", \"navy\", \"air force\", \"space force\", \"missile defense\",\n",
    "    \"awarded a contract\", \"received a contract\", \"contract value\",\n",
    "    \"multi-year contract\", \"indefinite delivery\", \"ceiling value\",\n",
    "    \"nasa\", \"faa\", \"homeland security\"\n",
    "]\n",
    "\n",
    "# Our sectors of interest\n",
    "SECTOR_TICKERS = {\n",
    "    'defense': ['LMT', 'NOC', 'RTX', 'GD', 'LHX', 'KTOS', 'PLTR', 'BBAI'],\n",
    "    'space': ['RKLB', 'LUNR', 'ASTS', 'SPCE', 'MNTS'],\n",
    "    'ai_infra': ['MU', 'VRT', 'NVDA', 'AMD', 'AVGO', 'MRVL'],\n",
    "    'nuclear': ['CCJ', 'LEU', 'OKLO', 'SMR', 'VST', 'CEG'],\n",
    "    'small_cap_defense': ['SIDU', 'BBAI', 'KTOS', 'MRCY']\n",
    "}\n",
    "\n",
    "# Flatten for easy access\n",
    "ALL_TICKERS = list(set([t for sector in SECTOR_TICKERS.values() for t in sector]))\n",
    "\n",
    "print(f\"üìä Configuration Loaded\")\n",
    "print(f\"   Tracking {len(ALL_TICKERS)} tickers across {len(SECTOR_TICKERS)} sectors\")\n",
    "print(f\"   Contract keywords: {len(CONTRACT_KEYWORDS)} phrases\")\n",
    "print(f\"\\nSectors:\")\n",
    "for sector, tickers in SECTOR_TICKERS.items():\n",
    "    print(f\"   {sector:20} | {len(tickers)} tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: SEC FILING FETCHER\n",
    "# ============================================================\n",
    "\n",
    "def get_company_cik(ticker: str) -> Optional[str]:\n",
    "    \"\"\"Get CIK number for a ticker from SEC.\"\"\"\n",
    "    try:\n",
    "        # Try the company tickers JSON first (faster)\n",
    "        url = f\"{SEC_BASE_URL}/files/company_tickers.json\"\n",
    "        response = requests.get(url, headers=SEC_HEADERS, timeout=10)\n",
    "        data = response.json()\n",
    "        \n",
    "        for entry in data.values():\n",
    "            if entry.get('ticker', '').upper() == ticker.upper():\n",
    "                return str(entry['cik_str']).zfill(10)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_8k_filings(cik: str, start_date: str, end_date: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Get all 8-K filings for a company in date range.\n",
    "    Returns list of filing metadata.\n",
    "    \"\"\"\n",
    "    filings = []\n",
    "    \n",
    "    try:\n",
    "        # Get submissions using the modern API\n",
    "        url = f\"{SEC_BASE_URL}/submissions/CIK{cik}.json\"\n",
    "        response = requests.get(url, headers=SEC_HEADERS, timeout=15)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Parse recent filings\n",
    "        recent = data.get('filings', {}).get('recent', {})\n",
    "        forms = recent.get('form', [])\n",
    "        dates = recent.get('filingDate', [])\n",
    "        accessions = recent.get('accessionNumber', [])\n",
    "        \n",
    "        for i, form in enumerate(forms):\n",
    "            if form == '8-K':\n",
    "                filing_date = dates[i]\n",
    "                \n",
    "                # Check date range\n",
    "                if filing_date >= start_date and filing_date <= end_date:\n",
    "                    filings.append({\n",
    "                        'date': filing_date,\n",
    "                        'type': '8-K',\n",
    "                        'accession': accessions[i],\n",
    "                        'cik': cik\n",
    "                    })\n",
    "        \n",
    "        time.sleep(0.15)  # SEC rate limiting\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Error fetching 8-K for CIK {cik}: {e}\")\n",
    "    \n",
    "    return filings\n",
    "\n",
    "\n",
    "def get_filing_text(cik: str, accession: str) -> str:\n",
    "    \"\"\"Get the text content of an 8-K filing.\"\"\"\n",
    "    try:\n",
    "        # Format accession for URL\n",
    "        acc_formatted = accession.replace('-', '')\n",
    "        url = f\"{SEC_BASE_URL}/Archives/edgar/data/{int(cik)}/{acc_formatted}/{accession}.txt\"\n",
    "        \n",
    "        response = requests.get(url, headers=SEC_HEADERS, timeout=15)\n",
    "        time.sleep(0.15)  # Rate limiting\n",
    "        \n",
    "        return response.text.lower()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def contains_contract_keywords(text: str) -> Tuple[bool, List[str]]:\n",
    "    \"\"\"Check if filing text contains contract-related keywords.\"\"\"\n",
    "    found = []\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    for keyword in CONTRACT_KEYWORDS:\n",
    "        if keyword in text_lower:\n",
    "            found.append(keyword)\n",
    "    \n",
    "    return len(found) > 0, found\n",
    "\n",
    "print(\"‚úÖ SEC Filing Functions Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73150646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: PRICE DATA FETCHER\n",
    "# ============================================================\n",
    "\n",
    "def get_price_reaction(ticker: str, event_date: str, days_before: int = 5, days_after: int = 20) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Get price reaction around an event date.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with price changes at various intervals (1d, 2d, 3d, 5d, 10d, 20d)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse date\n",
    "        event_dt = datetime.strptime(event_date, '%Y-%m-%d')\n",
    "        start_dt = event_dt - timedelta(days=days_before + 10)  # Buffer for trading days\n",
    "        end_dt = event_dt + timedelta(days=days_after + 10)\n",
    "        \n",
    "        # Fetch data\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(start=start_dt.strftime('%Y-%m-%d'), \n",
    "                            end=end_dt.strftime('%Y-%m-%d'))\n",
    "        \n",
    "        if hist.empty or len(hist) < 10:\n",
    "            return None\n",
    "        \n",
    "        # Find the event date in data (or closest trading day after)\n",
    "        hist.index = hist.index.tz_localize(None)\n",
    "        event_idx = None\n",
    "        \n",
    "        for i in range(5):  # Look up to 5 days forward for trading day\n",
    "            check_date = event_dt + timedelta(days=i)\n",
    "            matches = hist.index[hist.index.date == check_date.date()]\n",
    "            if len(matches) > 0:\n",
    "                event_idx = hist.index.get_loc(matches[0])\n",
    "                break\n",
    "        \n",
    "        if event_idx is None:\n",
    "            return None\n",
    "        \n",
    "        # Get prices at key points\n",
    "        event_close = hist.iloc[event_idx]['Close']\n",
    "        \n",
    "        # Price before event (1 day before)\n",
    "        pre_idx = max(0, event_idx - 1)\n",
    "        pre_close = hist.iloc[pre_idx]['Close']\n",
    "        \n",
    "        # Calculate returns at different intervals\n",
    "        returns = {}\n",
    "        \n",
    "        intervals = [1, 2, 3, 5, 10, 20]\n",
    "        for days in intervals:\n",
    "            future_idx = min(len(hist) - 1, event_idx + days)\n",
    "            if future_idx > event_idx:\n",
    "                future_close = hist.iloc[future_idx]['Close']\n",
    "                returns[f'return_{days}d'] = ((future_close - event_close) / event_close) * 100\n",
    "            else:\n",
    "                returns[f'return_{days}d'] = None\n",
    "        \n",
    "        # Overnight gap (event day open vs previous close)\n",
    "        event_open = hist.iloc[event_idx]['Open']\n",
    "        overnight_gap = ((event_open - pre_close) / pre_close) * 100\n",
    "        \n",
    "        return {\n",
    "            'ticker': ticker,\n",
    "            'event_date': event_date,\n",
    "            'pre_close': round(pre_close, 2),\n",
    "            'event_close': round(event_close, 2),\n",
    "            'overnight_gap': round(overnight_gap, 2),\n",
    "            **{k: round(v, 2) if v else None for k, v in returns.items()}\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Price Reaction Functions Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca575911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: MAIN BACKTEST FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def backtest_contract_announcements(\n",
    "    tickers: List[str],\n",
    "    start_date: str = \"2023-01-01\",\n",
    "    end_date: str = \"2025-12-31\",\n",
    "    min_keywords: int = 2\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Backtest: What happens after 8-K filings with contract keywords?\n",
    "    \n",
    "    Args:\n",
    "        tickers: List of tickers to analyze\n",
    "        start_date: Start of analysis period\n",
    "        end_date: End of analysis period\n",
    "        min_keywords: Minimum keyword matches to count as contract news\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with all contract events and price reactions\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\nüê∫ WOLF PACK BACKTEST: CONTRACT ANNOUNCEMENTS\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"Analyzing {len(tickers)} tickers from {start_date} to {end_date}\")\n",
    "    print(f\"Looking for filings with {min_keywords}+ contract keywords\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    for ticker in tqdm(tickers, desc=\"üê∫ Processing tickers\"):\n",
    "        try:\n",
    "            # Get CIK\n",
    "            cik = get_company_cik(ticker)\n",
    "            if not cik:\n",
    "                print(f\"  ‚ö†Ô∏è  {ticker}: CIK not found\")\n",
    "                continue\n",
    "            \n",
    "            # Get 8-K filings\n",
    "            filings = get_8k_filings(cik, start_date, end_date)\n",
    "            \n",
    "            if len(filings) == 0:\n",
    "                continue\n",
    "            \n",
    "            for filing in filings:\n",
    "                # Get filing text\n",
    "                text = get_filing_text(cik, filing['accession'])\n",
    "                \n",
    "                if not text:\n",
    "                    continue\n",
    "                \n",
    "                # Check for contract keywords\n",
    "                has_contract, keywords = contains_contract_keywords(text)\n",
    "                \n",
    "                if has_contract and len(keywords) >= min_keywords:\n",
    "                    # Get price reaction\n",
    "                    reaction = get_price_reaction(ticker, filing['date'])\n",
    "                    \n",
    "                    if reaction:\n",
    "                        results.append({\n",
    "                            'ticker': ticker,\n",
    "                            'filing_date': filing['date'],\n",
    "                            'keywords_found': len(keywords),\n",
    "                            'keywords': ', '.join(keywords[:5]),\n",
    "                            **{k: v for k, v in reaction.items() if k not in ['ticker', 'event_date']}\n",
    "                        })\n",
    "                \n",
    "                time.sleep(0.1)  # Rate limiting\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error processing {ticker}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        print(f\"\\n‚úÖ Found {len(df)} contract announcement events!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No contract announcements found. Try different tickers or date range.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Backtest Function Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: ANALYSIS FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def analyze_results(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Analyze backtest results and show statistics.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No data to analyze.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüê∫ BACKTEST RESULTS ANALYSIS\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"Total Events: {len(df)}\")\n",
    "    print(f\"Unique Tickers: {df['ticker'].nunique()}\")\n",
    "    print(f\"Date Range: {df['filing_date'].min()} to {df['filing_date'].max()}\")\n",
    "    \n",
    "    # Return statistics at different intervals\n",
    "    print(f\"\\nüìä RETURN STATISTICS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return_cols = [c for c in df.columns if c.startswith('return_')]\n",
    "    \n",
    "    for col in return_cols:\n",
    "        valid_data = df[col].dropna()\n",
    "        if len(valid_data) > 0:\n",
    "            days = col.split('_')[1]\n",
    "            avg = valid_data.mean()\n",
    "            median = valid_data.median()\n",
    "            win_rate = (valid_data > 0).sum() / len(valid_data) * 100\n",
    "            \n",
    "            print(f\"  {days:>5} | Avg: {avg:+6.2f}% | Median: {median:+6.2f}% | Win Rate: {win_rate:.1f}%\")\n",
    "    \n",
    "    # Overnight gap stats\n",
    "    print(f\"\\nüìà OVERNIGHT GAP STATS:\")\n",
    "    print(\"-\" * 50)\n",
    "    gaps = df['overnight_gap'].dropna()\n",
    "    if len(gaps) > 0:\n",
    "        print(f\"  Average Gap: {gaps.mean():+.2f}%\")\n",
    "        print(f\"  Median Gap:  {gaps.median():+.2f}%\")\n",
    "        print(f\"  Gap Up Rate: {(gaps > 0).sum() / len(gaps) * 100:.1f}%\")\n",
    "    \n",
    "    # Best performers\n",
    "    print(f\"\\nüèÜ TOP 10 BEST REACTIONS (5-day return):\")\n",
    "    print(\"-\" * 50)\n",
    "    if 'return_5d' in df.columns:\n",
    "        top10 = df.nlargest(10, 'return_5d')[['ticker', 'filing_date', 'return_5d', 'keywords']]\n",
    "        for idx, row in top10.iterrows():\n",
    "            print(f\"  {row['ticker']:6} | {row['filing_date']} | {row['return_5d']:+6.2f}% | {str(row['keywords'])[:30]}...\")\n",
    "    \n",
    "    # By ticker\n",
    "    print(f\"\\nüìã BY TICKER (Avg 5-day return):\")\n",
    "    print(\"-\" * 50)\n",
    "    if 'return_5d' in df.columns:\n",
    "        by_ticker = df.groupby('ticker')['return_5d'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
    "        for ticker, row in by_ticker.head(10).iterrows():\n",
    "            print(f\"  {ticker:6} | Avg: {row['mean']:+6.2f}% | Events: {int(row['count'])}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_results(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Visualize backtest results.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. Distribution of overnight gaps\n",
    "    ax1 = axes[0, 0]\n",
    "    df['overnight_gap'].hist(bins=30, ax=ax1, color='steelblue', edgecolor='black')\n",
    "    ax1.axvline(x=0, color='red', linestyle='--', label='Zero')\n",
    "    ax1.axvline(x=df['overnight_gap'].mean(), color='green', linestyle='--', \n",
    "                label=f'Mean: {df[\"overnight_gap\"].mean():.2f}%')\n",
    "    ax1.set_title('üê∫ Distribution of Overnight Gaps', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Gap %')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Distribution of 5-day returns\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'return_5d' in df.columns:\n",
    "        df['return_5d'].dropna().hist(bins=30, ax=ax2, color='green', edgecolor='black')\n",
    "        ax2.axvline(x=0, color='red', linestyle='--')\n",
    "        ax2.axvline(x=df['return_5d'].mean(), color='blue', linestyle='--', \n",
    "                    label=f'Mean: {df[\"return_5d\"].mean():.2f}%')\n",
    "        ax2.set_title('üê∫ Distribution of 5-Day Returns', fontsize=12, fontweight='bold')\n",
    "        ax2.set_xlabel('Return %')\n",
    "        ax2.legend()\n",
    "    \n",
    "    # 3. Return by number of keywords\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'keywords_found' in df.columns and 'return_5d' in df.columns:\n",
    "        by_keywords = df.groupby('keywords_found')['return_5d'].mean()\n",
    "        by_keywords.plot(kind='bar', ax=ax3, color='purple', edgecolor='black')\n",
    "        ax3.set_title('üê∫ Avg 5-Day Return by # Keywords Found', fontsize=12, fontweight='bold')\n",
    "        ax3.set_xlabel('Number of Keywords')\n",
    "        ax3.set_ylabel('Avg Return %')\n",
    "        ax3.set_xticklabels(ax3.get_xticklabels(), rotation=0)\n",
    "    \n",
    "    # 4. Cumulative returns over time\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'return_5d' in df.columns:\n",
    "        df_sorted = df.sort_values('filing_date')\n",
    "        df_sorted['cumulative'] = df_sorted['return_5d'].fillna(0).cumsum()\n",
    "        ax4.plot(range(len(df_sorted)), df_sorted['cumulative'], color='green', linewidth=2)\n",
    "        ax4.fill_between(range(len(df_sorted)), df_sorted['cumulative'], alpha=0.3)\n",
    "        ax4.set_title('üê∫ Cumulative Returns (if traded each signal)', fontsize=12, fontweight='bold')\n",
    "        ax4.set_xlabel('Event Number')\n",
    "        ax4.set_ylabel('Cumulative Return %')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('backtest_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Charts saved to backtest_results.png\")\n",
    "\n",
    "\n",
    "def print_edge_summary(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Print the actionable edge we found.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n\")\n",
    "    print(f\"üê∫\" * 25)\n",
    "    print(f\"\\n        THE WOLF PACK EDGE - SUMMARY\\n\")\n",
    "    print(f\"üê∫\" * 25)\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    if 'return_5d' in df.columns:\n",
    "        avg_5d = df['return_5d'].mean()\n",
    "        win_rate = (df['return_5d'] > 0).sum() / len(df.dropna(subset=['return_5d'])) * 100\n",
    "        \n",
    "        print(f\"\"\"\n",
    "WHAT WE FOUND:\n",
    "--------------\n",
    "After a company announces a government/defense contract (8-K filing):\n",
    "\n",
    "  üìà Average 5-day return: {avg_5d:+.2f}%\n",
    "  üéØ Win rate: {win_rate:.1f}%\n",
    "  üìä Sample size: {len(df)} events\n",
    "\n",
    "THE EDGE:\n",
    "---------\n",
    "If we had bought every stock the day a contract 8-K was filed\n",
    "and sold 5 days later:\n",
    "\n",
    "  ‚úÖ We would have been RIGHT {win_rate:.0f}% of the time\n",
    "  ‚úÖ Average gain per trade: {avg_5d:.2f}%\n",
    "  ‚úÖ Expected value is {'POSITIVE ‚úÖ' if avg_5d > 0 else 'NEGATIVE ‚ö†Ô∏è'}\n",
    "\n",
    "HOW TO USE THIS:\n",
    "----------------\n",
    "1. Run the scanner daily to catch new 8-K filings\n",
    "2. When contract keywords detected ‚Üí ALERT\n",
    "3. Enter position same day or next morning\n",
    "4. Hold for 3-5 days\n",
    "5. Take profits at target\n",
    "\n",
    "REMEMBER:\n",
    "---------\n",
    "- This is a STATISTICAL edge, not a guarantee\n",
    "- Use proper position sizing (5-10% of account)\n",
    "- Set stop losses (Wolf Pack 2% risk rule)\n",
    "- The edge works OVER TIME, not every trade\n",
    "\n",
    "AWOOOO üê∫\n",
    "        \"\"\")\n",
    "\n",
    "print(\"‚úÖ Analysis Functions Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864499f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: RUN BACKTEST - DEFENSE SECTOR\n",
    "# ============================================================\n",
    "\n",
    "# Run backtest on defense sector (most likely to have contract news)\n",
    "print(\"üê∫ Running defense sector backtest...\")\n",
    "print(\"‚è±Ô∏è  This will take 5-15 minutes depending on SEC API speed...\\n\")\n",
    "\n",
    "defense_tickers = SECTOR_TICKERS['defense'] + SECTOR_TICKERS['small_cap_defense']\n",
    "\n",
    "defense_results = backtest_contract_announcements(\n",
    "    tickers=list(set(defense_tickers)),  # Remove duplicates\n",
    "    start_date=\"2024-01-01\",  # Last year\n",
    "    end_date=\"2025-12-31\",\n",
    "    min_keywords=2  # Must have at least 2 contract keywords\n",
    ")\n",
    "\n",
    "# Analyze and visualize\n",
    "if not defense_results.empty:\n",
    "    analyze_results(defense_results)\n",
    "    plot_results(defense_results)\n",
    "    print_edge_summary(defense_results)\n",
    "    \n",
    "    # Save for later use\n",
    "    defense_results.to_csv('defense_backtest_results.csv', index=False)\n",
    "    print(\"\\nüíæ Results saved to defense_backtest_results.csv\")\n",
    "    print(\"   You can load this later with: df = pd.read_csv('defense_backtest_results.csv')\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No results found. This could mean:\")\n",
    "    print(\"   - SEC API is down or rate limiting\")\n",
    "    print(\"   - No contract announcements in this period\")\n",
    "    print(\"   - Try running with min_keywords=1 instead of 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: QUICK SINGLE TICKER ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "def quick_ticker_analysis(ticker: str, days: int = 365):\n",
    "    \"\"\"\n",
    "    Quick analysis of a single ticker's contract announcements.\n",
    "    \"\"\"\n",
    "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    start_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"\\nüê∫ QUICK ANALYSIS: {ticker}\")\n",
    "    print(f\"Period: Last {days} days ({start_date} to {end_date})\\n\")\n",
    "    \n",
    "    results = backtest_contract_announcements(\n",
    "        tickers=[ticker],\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        min_keywords=1  # Lower threshold for single ticker\n",
    "    )\n",
    "    \n",
    "    if not results.empty:\n",
    "        analyze_results(results)\n",
    "        if len(results) >= 3:  # Only plot if we have enough data\n",
    "            plot_results(results)\n",
    "        return results\n",
    "    else:\n",
    "        print(f\"‚ùå No contract announcements found for {ticker}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example: Analyze SIDU (the one that ran 218%)\n",
    "# Uncomment to run:\n",
    "# sidu_results = quick_ticker_analysis('SIDU', days=180)\n",
    "\n",
    "# Or try PLTR:\n",
    "# pltr_results = quick_ticker_analysis('PLTR', days=365)\n",
    "\n",
    "print(\"\\nüí° To analyze a specific ticker, run:\")\n",
    "print(\"   results = quick_ticker_analysis('TICKER', days=365)\")\n",
    "print(\"\\n   Examples:\")\n",
    "print(\"   - quick_ticker_analysis('SIDU', days=180)\")\n",
    "print(\"   - quick_ticker_analysis('PLTR', days=365)\")\n",
    "print(\"   - quick_ticker_analysis('BBAI', days=90)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bec498f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üê∫ WOLF PACK BACKTEST COMPLETE\n",
    "\n",
    "### What You Have Now:\n",
    "\n",
    "1. **Backtest results** showing actual historical edge\n",
    "2. **Statistical analysis** (win rate, avg returns, etc.)\n",
    "3. **Visualizations** (charts saved to backtest_results.png)\n",
    "4. **CSV export** (defense_backtest_results.csv)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Run more sectors**:\n",
    "   ```python\n",
    "   space_results = backtest_contract_announcements(\n",
    "       tickers=SECTOR_TICKERS['space'],\n",
    "       start_date=\"2024-01-01\",\n",
    "       end_date=\"2025-12-31\"\n",
    "   )\n",
    "   ```\n",
    "\n",
    "2. **Analyze specific tickers**:\n",
    "   ```python\n",
    "   sidu = quick_ticker_analysis('SIDU', days=180)\n",
    "   ```\n",
    "\n",
    "3. **Combine with live scanner**:\n",
    "   - Use this backtest data to validate the edge\n",
    "   - When scanner alerts ‚Üí check if it fits the pattern\n",
    "   - Trade with confidence knowing the statistics\n",
    "\n",
    "**AWOOOO üê∫ - The Pack Hunts With Data**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
