{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d8e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê∫ PRE-MARKET SIGNAL ANALYSIS\n",
      "============================================================\n",
      "Date: 2026-01-06 23:00\n",
      "Mission: Test if Day 1's announce in pre-market\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üê∫ PRE-MARKET SIGNAL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"Mission: Test if Day 1's announce in pre-market\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb2e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Testing 21 stocks for pre-market signals\n"
     ]
    }
   ],
   "source": [
    "# Test universe - same as other notebooks\n",
    "UNIVERSE = [\n",
    "    'SIDU', 'ASTS', 'LUNR', 'RKLB', 'RDW',  # Space\n",
    "    'IONQ', 'QBTS', 'RGTI', 'QUBT',          # Quantum\n",
    "    'NVTS', 'WOLF', 'ON', 'AEHR', 'SKYT',    # Semi\n",
    "    'UUUU', 'LEU', 'CCJ', 'SMR', 'OKLO',     # Nuclear\n",
    "    'USAR', 'MP'                             # Rare Earth\n",
    "]\n",
    "\n",
    "print(f\"üìä Testing {len(UNIVERSE)} stocks for pre-market signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6683434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ get_daily_data() ready\n"
     ]
    }
   ],
   "source": [
    "def get_daily_data(ticker, lookback_months=6):\n",
    "    \"\"\"\n",
    "    Get daily OHLCV data with gap calculations.\n",
    "    \n",
    "    NOTE: yfinance doesn't have reliable pre-market data for small caps.\n",
    "    We'll use open vs previous close as proxy for \"gap\" which captures\n",
    "    overnight/pre-market movement.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=lookback_months * 30)\n",
    "        \n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(start=start_date, end=end_date)\n",
    "        \n",
    "        if len(hist) < 20:\n",
    "            return None\n",
    "        \n",
    "        # Calculate gap (Open vs Previous Close)\n",
    "        hist['prev_close'] = hist['Close'].shift(1)\n",
    "        hist['gap_pct'] = ((hist['Open'] - hist['prev_close']) / hist['prev_close']) * 100\n",
    "        \n",
    "        # Daily return (Close vs Open) - intraday movement\n",
    "        hist['intraday_pct'] = ((hist['Close'] - hist['Open']) / hist['Open']) * 100\n",
    "        \n",
    "        # Full day return (Close vs Previous Close)\n",
    "        hist['daily_pct'] = ((hist['Close'] - hist['prev_close']) / hist['prev_close']) * 100\n",
    "        \n",
    "        # Volume ratio\n",
    "        hist['vol_ratio'] = hist['Volume'] / hist['Volume'].rolling(20).mean()\n",
    "        \n",
    "        # Is this a green day?\n",
    "        hist['is_green'] = hist['Close'] > hist['Open']\n",
    "        \n",
    "        return hist\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ get_daily_data() ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345b4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ find_day1s() ready\n"
     ]
    }
   ],
   "source": [
    "def find_day1s(hist, min_run_days=3, min_gain=10):\n",
    "    \"\"\"\n",
    "    Find all Day 1's (first day of a 3+ day run).\n",
    "    Returns list of Day 1 info with gap data.\n",
    "    \"\"\"\n",
    "    day1s = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(hist) - min_run_days:\n",
    "        # Check if this day starts a run\n",
    "        if hist['daily_pct'].iloc[i] > 0:  # Green day\n",
    "            run_length = 1\n",
    "            j = i + 1\n",
    "            \n",
    "            # Count consecutive green days\n",
    "            while j < len(hist) and hist['daily_pct'].iloc[j] > 0:\n",
    "                run_length += 1\n",
    "                j += 1\n",
    "            \n",
    "            if run_length >= min_run_days:\n",
    "                # Calculate total run gain\n",
    "                end_idx = min(i + run_length, len(hist) - 1)\n",
    "                start_price = hist['prev_close'].iloc[i]\n",
    "                end_price = hist['Close'].iloc[end_idx - 1]\n",
    "                \n",
    "                if pd.notna(start_price) and start_price > 0:\n",
    "                    total_gain = ((end_price / start_price) - 1) * 100\n",
    "                    \n",
    "                    if total_gain >= min_gain:\n",
    "                        day1s.append({\n",
    "                            'date': hist.index[i],\n",
    "                            'gap_pct': hist['gap_pct'].iloc[i],\n",
    "                            'day1_gain': hist['daily_pct'].iloc[i],\n",
    "                            'intraday': hist['intraday_pct'].iloc[i],\n",
    "                            'vol_ratio': hist['vol_ratio'].iloc[i],\n",
    "                            'run_length': run_length,\n",
    "                            'run_gain': total_gain,\n",
    "                            'open': hist['Open'].iloc[i],\n",
    "                            'prev_close': hist['prev_close'].iloc[i]\n",
    "                        })\n",
    "                \n",
    "                i = j\n",
    "                continue\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return day1s\n",
    "\n",
    "print(\"‚úÖ find_day1s() ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4e9c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä COLLECTING DAY 1 GAP DATA\n",
      "============================================================\n",
      "   SIDU: 7 Day 1's found\n",
      "   ASTS: 10 Day 1's found\n",
      "   LUNR: 8 Day 1's found\n",
      "   RKLB: 8 Day 1's found\n",
      "   RDW: 6 Day 1's found\n",
      "   IONQ: 8 Day 1's found\n",
      "   QBTS: 9 Day 1's found\n",
      "   RGTI: 10 Day 1's found\n",
      "   QUBT: 6 Day 1's found\n",
      "   NVTS: 6 Day 1's found\n",
      "   WOLF: 2 Day 1's found\n",
      "   ON: 1 Day 1's found\n",
      "   AEHR: 6 Day 1's found\n",
      "   SKYT: 6 Day 1's found\n",
      "   UUUU: 9 Day 1's found\n",
      "   LEU: 5 Day 1's found\n",
      "   CCJ: 2 Day 1's found\n",
      "   SMR: 7 Day 1's found\n",
      "   OKLO: 9 Day 1's found\n",
      "   USAR: 5 Day 1's found\n",
      "   MP: 6 Day 1's found\n",
      "\n",
      "üìä TOTAL: 136 Day 1's across all stocks\n"
     ]
    }
   ],
   "source": [
    "# COLLECT ALL DAY 1 DATA\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COLLECTING DAY 1 GAP DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_day1s = []\n",
    "\n",
    "for ticker in UNIVERSE:\n",
    "    hist = get_daily_data(ticker)\n",
    "    if hist is None:\n",
    "        continue\n",
    "    \n",
    "    day1s = find_day1s(hist)\n",
    "    \n",
    "    for d1 in day1s:\n",
    "        d1['ticker'] = ticker\n",
    "        all_day1s.append(d1)\n",
    "    \n",
    "    if day1s:\n",
    "        print(f\"   {ticker}: {len(day1s)} Day 1's found\")\n",
    "\n",
    "print(f\"\\nüìä TOTAL: {len(all_day1s)} Day 1's across all stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b98e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä GAP PATTERN ANALYSIS\n",
      "============================================================\n",
      "\n",
      "üìà GAP STATISTICS (n=136 Day 1's):\n",
      "----------------------------------------\n",
      "   Average gap on Day 1: 1.89%\n",
      "   Median gap: 0.97%\n",
      "   Min gap: -4.19%\n",
      "   Max gap: 19.46%\n",
      "\n",
      "üìä GAP DISTRIBUTION:\n",
      "----------------------------------------\n",
      "   Gap DOWN (<-1%):       7 (5%)\n",
      "   Gap FLAT (-1% to 1%):  62 (46%)\n",
      "   Gap SMALL (1-3%):     32 (24%)\n",
      "   Gap MEDIUM (3-5%):    18 (13%)\n",
      "   Gap LARGE (5%+):      17 (12%)\n",
      "\n",
      "üìä KEY FINDING:\n",
      "   Day 1's that gap UP: 75%\n",
      "   Day 1's with 2%+ gap: 35%\n",
      "   Day 1's with 3%+ gap: 26%\n"
     ]
    }
   ],
   "source": [
    "# ANALYZE GAP PATTERNS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä GAP PATTERN ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if all_day1s:\n",
    "    df = pd.DataFrame(all_day1s)\n",
    "    \n",
    "    # Filter out any invalid gap data\n",
    "    df = df[df['gap_pct'].notna()]\n",
    "    \n",
    "    print(f\"\\nüìà GAP STATISTICS (n={len(df)} Day 1's):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"   Average gap on Day 1: {df['gap_pct'].mean():.2f}%\")\n",
    "    print(f\"   Median gap: {df['gap_pct'].median():.2f}%\")\n",
    "    print(f\"   Min gap: {df['gap_pct'].min():.2f}%\")\n",
    "    print(f\"   Max gap: {df['gap_pct'].max():.2f}%\")\n",
    "    \n",
    "    # Categorize gaps\n",
    "    gap_down = (df['gap_pct'] < -1).sum()\n",
    "    gap_flat = ((df['gap_pct'] >= -1) & (df['gap_pct'] < 1)).sum()\n",
    "    gap_small = ((df['gap_pct'] >= 1) & (df['gap_pct'] < 3)).sum()\n",
    "    gap_medium = ((df['gap_pct'] >= 3) & (df['gap_pct'] < 5)).sum()\n",
    "    gap_large = (df['gap_pct'] >= 5).sum()\n",
    "    \n",
    "    print(f\"\\nüìä GAP DISTRIBUTION:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   Gap DOWN (<-1%):     {gap_down:3d} ({gap_down/len(df)*100:.0f}%)\")\n",
    "    print(f\"   Gap FLAT (-1% to 1%): {gap_flat:3d} ({gap_flat/len(df)*100:.0f}%)\")\n",
    "    print(f\"   Gap SMALL (1-3%):    {gap_small:3d} ({gap_small/len(df)*100:.0f}%)\")\n",
    "    print(f\"   Gap MEDIUM (3-5%):   {gap_medium:3d} ({gap_medium/len(df)*100:.0f}%)\")\n",
    "    print(f\"   Gap LARGE (5%+):     {gap_large:3d} ({gap_large/len(df)*100:.0f}%)\")\n",
    "    \n",
    "    # What % gap up?\n",
    "    gap_up_pct = (df['gap_pct'] > 0).sum() / len(df) * 100\n",
    "    gap_up_2pct = (df['gap_pct'] >= 2).sum() / len(df) * 100\n",
    "    gap_up_3pct = (df['gap_pct'] >= 3).sum() / len(df) * 100\n",
    "    \n",
    "    print(f\"\\nüìä KEY FINDING:\")\n",
    "    print(f\"   Day 1's that gap UP: {gap_up_pct:.0f}%\")\n",
    "    print(f\"   Day 1's with 2%+ gap: {gap_up_2pct:.0f}%\")\n",
    "    print(f\"   Day 1's with 3%+ gap: {gap_up_3pct:.0f}%\")\n",
    "else:\n",
    "    print(\"‚ùå No Day 1 data collected\")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669ecf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä GAP SIZE vs RUN SUCCESS\n",
      "============================================================\n",
      "\n",
      "Gap Size                Count    Avg Run   Avg Days\n",
      "--------------------------------------------------\n",
      "Gap Down                   29      28.1%        4.5\n",
      "Small (0-2%)               60      26.9%        4.3\n",
      "Medium (2-4%)              22      24.6%        3.9\n",
      "Large (4%+)                25      32.9%        3.4\n",
      "\n",
      "üìà Correlation (gap vs run gain): 0.18\n",
      "   ‚ö†Ô∏è WEAK CORRELATION: Gap size doesn't predict run size\n"
     ]
    }
   ],
   "source": [
    "# CORRELATION: GAP SIZE vs RUN SUCCESS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä GAP SIZE vs RUN SUCCESS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(df) > 0:\n",
    "    # Group by gap size buckets\n",
    "    def gap_bucket(gap):\n",
    "        if gap < 0:\n",
    "            return 'Gap Down'\n",
    "        elif gap < 2:\n",
    "            return 'Small (0-2%)'\n",
    "        elif gap < 4:\n",
    "            return 'Medium (2-4%)'\n",
    "        else:\n",
    "            return 'Large (4%+)'\n",
    "    \n",
    "    df['gap_bucket'] = df['gap_pct'].apply(gap_bucket)\n",
    "    \n",
    "    print(f\"\\n{'Gap Size':<20} {'Count':>8} {'Avg Run':>10} {'Avg Days':>10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for bucket in ['Gap Down', 'Small (0-2%)', 'Medium (2-4%)', 'Large (4%+)']:\n",
    "        bucket_data = df[df['gap_bucket'] == bucket]\n",
    "        if len(bucket_data) > 0:\n",
    "            avg_gain = bucket_data['run_gain'].mean()\n",
    "            avg_days = bucket_data['run_length'].mean()\n",
    "            print(f\"{bucket:<20} {len(bucket_data):>8} {avg_gain:>9.1f}% {avg_days:>10.1f}\")\n",
    "    \n",
    "    # Correlation coefficient\n",
    "    corr = df['gap_pct'].corr(df['run_gain'])\n",
    "    print(f\"\\nüìà Correlation (gap vs run gain): {corr:.2f}\")\n",
    "    \n",
    "    if corr > 0.3:\n",
    "        print(f\"   ‚úÖ POSITIVE CORRELATION: Bigger gaps = bigger runs\")\n",
    "    elif corr < -0.1:\n",
    "        print(f\"   ‚ö†Ô∏è NEGATIVE CORRELATION: Smaller gaps = bigger runs\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è WEAK CORRELATION: Gap size doesn't predict run size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3cffdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä FALSE SIGNAL ANALYSIS\n",
      "============================================================\n",
      "\n",
      "What happens when there's a gap UP but NO run?\n",
      "\n",
      "Found 292 false signals (3%+ gap that didn't start a run)\n",
      "\n",
      "üìä 3%+ GAP SIGNAL QUALITY:\n",
      "----------------------------------------\n",
      "   Total 3%+ gaps: 327\n",
      "   True positives (started run): 35 (11%)\n",
      "   False positives (no run): 292 (89%)\n",
      "\n",
      "   ‚ö†Ô∏è 3%+ GAP HAS HIGH FALSE POSITIVE RATE\n",
      "   Need additional confirmation signals\n"
     ]
    }
   ],
   "source": [
    "# FALSE SIGNAL ANALYSIS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FALSE SIGNAL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nWhat happens when there's a gap UP but NO run?\\n\")\n",
    "\n",
    "# Find all gap-ups that DIDN'T become Day 1's\n",
    "false_signals = []\n",
    "\n",
    "for ticker in UNIVERSE:\n",
    "    hist = get_daily_data(ticker)\n",
    "    if hist is None:\n",
    "        continue\n",
    "    \n",
    "    # Get Day 1 dates for this ticker\n",
    "    day1s = find_day1s(hist)\n",
    "    day1_dates = set([d['date'] for d in day1s])\n",
    "    \n",
    "    # Find gap-ups (3%+) that weren't Day 1's\n",
    "    for i in range(1, len(hist)):\n",
    "        gap = hist['gap_pct'].iloc[i]\n",
    "        date = hist.index[i]\n",
    "        \n",
    "        if pd.notna(gap) and gap >= 3:  # 3%+ gap up\n",
    "            if date not in day1_dates:\n",
    "                # This is a false signal\n",
    "                false_signals.append({\n",
    "                    'ticker': ticker,\n",
    "                    'date': date,\n",
    "                    'gap_pct': gap,\n",
    "                    'daily_pct': hist['daily_pct'].iloc[i],\n",
    "                    'vol_ratio': hist['vol_ratio'].iloc[i]\n",
    "                })\n",
    "\n",
    "print(f\"Found {len(false_signals)} false signals (3%+ gap that didn't start a run)\")\n",
    "\n",
    "# Compare true vs false signals\n",
    "if len(df) > 0 and len(false_signals) > 0:\n",
    "    true_3pct = df[df['gap_pct'] >= 3]\n",
    "    \n",
    "    total_3pct_gaps = len(true_3pct) + len(false_signals)\n",
    "    true_positive_rate = len(true_3pct) / total_3pct_gaps * 100\n",
    "    false_positive_rate = len(false_signals) / total_3pct_gaps * 100\n",
    "    \n",
    "    print(f\"\\nüìä 3%+ GAP SIGNAL QUALITY:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   Total 3%+ gaps: {total_3pct_gaps}\")\n",
    "    print(f\"   True positives (started run): {len(true_3pct)} ({true_positive_rate:.0f}%)\")\n",
    "    print(f\"   False positives (no run): {len(false_signals)} ({false_positive_rate:.0f}%)\")\n",
    "    \n",
    "    if true_positive_rate >= 60:\n",
    "        print(f\"\\n   ‚úÖ 3%+ GAP IS A RELIABLE SIGNAL\")\n",
    "    else:\n",
    "        print(f\"\\n   ‚ö†Ô∏è 3%+ GAP HAS HIGH FALSE POSITIVE RATE\")\n",
    "        print(f\"   Need additional confirmation signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62bfd2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä VOLUME AS GAP CONFIRMATION\n",
      "============================================================\n",
      "\n",
      "üìà Day 1 Volume Stats:\n",
      "   Average volume ratio: 1.0x normal\n",
      "   Median volume ratio: 0.9x normal\n",
      "\n",
      "   Day 1's with 1.5x volume: 17%\n",
      "   Day 1's with 2x+ volume: 4%\n",
      "\n",
      "üìä TRUE vs FALSE SIGNAL VOLUME:\n",
      "   True Day 1 avg volume: 1.0x\n",
      "   False gap avg volume: 1.6x\n",
      "\n",
      "   ‚ö†Ô∏è Volume doesn't differentiate true vs false gaps\n"
     ]
    }
   ],
   "source": [
    "# VOLUME AS CONFIRMATION\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä VOLUME AS GAP CONFIRMATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(df) > 0:\n",
    "    # For true Day 1's, what's the volume ratio?\n",
    "    vol_ratios = df['vol_ratio'].dropna()\n",
    "    \n",
    "    print(f\"\\nüìà Day 1 Volume Stats:\")\n",
    "    print(f\"   Average volume ratio: {vol_ratios.mean():.1f}x normal\")\n",
    "    print(f\"   Median volume ratio: {vol_ratios.median():.1f}x normal\")\n",
    "    \n",
    "    # What % have elevated volume?\n",
    "    elevated_vol = (vol_ratios >= 1.5).sum() / len(vol_ratios) * 100\n",
    "    high_vol = (vol_ratios >= 2.0).sum() / len(vol_ratios) * 100\n",
    "    \n",
    "    print(f\"\\n   Day 1's with 1.5x volume: {elevated_vol:.0f}%\")\n",
    "    print(f\"   Day 1's with 2x+ volume: {high_vol:.0f}%\")\n",
    "    \n",
    "    # Compare volume on true Day 1's vs false gaps\n",
    "    if false_signals:\n",
    "        false_vol = pd.DataFrame(false_signals)['vol_ratio'].dropna().mean()\n",
    "        true_vol = vol_ratios.mean()\n",
    "        \n",
    "        print(f\"\\nüìä TRUE vs FALSE SIGNAL VOLUME:\")\n",
    "        print(f\"   True Day 1 avg volume: {true_vol:.1f}x\")\n",
    "        print(f\"   False gap avg volume: {false_vol:.1f}x\")\n",
    "        \n",
    "        if true_vol > false_vol * 1.2:\n",
    "            print(f\"\\n   ‚úÖ VOLUME IS A CONFIRMING SIGNAL\")\n",
    "            print(f\"   True Day 1's have ~{true_vol/false_vol:.0f}x more volume than false gaps\")\n",
    "        else:\n",
    "            print(f\"\\n   ‚ö†Ô∏è Volume doesn't differentiate true vs false gaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668bd314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä COMBINED SIGNAL: GAP + VOLUME\n",
      "============================================================\n",
      "\n",
      "üìä Signal Quality Comparison:\n",
      "----------------------------------------\n",
      "   Gap only (2%+): 47 Day 1's\n",
      "   Gap + Volume: 13 Day 1's\n",
      "\n",
      "   Avg run gain (gap only): 29.0%\n",
      "   Avg run gain (gap+vol): 35.9%\n",
      "\n",
      "   ‚úÖ COMBINED SIGNAL PRODUCES BETTER RUNS\n",
      "   Using Gap + Volume confirmation improves avg gain by 24%\n"
     ]
    }
   ],
   "source": [
    "# COMBINED SIGNAL: GAP + VOLUME\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COMBINED SIGNAL: GAP + VOLUME\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(df) > 0:\n",
    "    # Test: Gap 2%+ AND Volume 1.5x+\n",
    "    combined_signal = df[(df['gap_pct'] >= 2) & (df['vol_ratio'] >= 1.5)]\n",
    "    just_gap = df[df['gap_pct'] >= 2]\n",
    "    \n",
    "    print(f\"\\nüìä Signal Quality Comparison:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   Gap only (2%+): {len(just_gap)} Day 1's\")\n",
    "    print(f\"   Gap + Volume: {len(combined_signal)} Day 1's\")\n",
    "    \n",
    "    if len(combined_signal) > 5:\n",
    "        # Compare run quality\n",
    "        gap_only_avg = just_gap['run_gain'].mean()\n",
    "        combined_avg = combined_signal['run_gain'].mean()\n",
    "        \n",
    "        print(f\"\\n   Avg run gain (gap only): {gap_only_avg:.1f}%\")\n",
    "        print(f\"   Avg run gain (gap+vol): {combined_avg:.1f}%\")\n",
    "        \n",
    "        if combined_avg > gap_only_avg * 1.1:\n",
    "            print(f\"\\n   ‚úÖ COMBINED SIGNAL PRODUCES BETTER RUNS\")\n",
    "            print(f\"   Using Gap + Volume confirmation improves avg gain by {(combined_avg/gap_only_avg-1)*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "967bf52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ THESIS VERDICT: PRE-MARKET SIGNALS\n",
      "================================================================================\n",
      "\n",
      "üìä SUMMARY:\n",
      "----------------------------------------\n",
      "   Total Day 1's analyzed: 136\n",
      "   Day 1's that gap UP: 75%\n",
      "   Day 1's with 3%+ gap: 26%\n",
      "   Average volume on Day 1: 1.0x normal\n",
      "\n",
      "‚úÖ THESIS VALIDATED: Day 1's DO gap up in pre-market\n",
      "   75% of Day 1's show overnight/pre-market strength\n",
      "\n",
      "üìã ACTIONABLE ENTRY RULES:\n",
      "   1. Look for any gap UP on stocks showing Day 0 signals\n",
      "   2. Confirm with elevated volume (1x+ normal)\n",
      "   3. Enter within first 30 min of market open\n",
      "   4. Hold for expected run duration (from Notebook 1)\n",
      "\n",
      "================================================================================\n",
      "NEXT: Run Notebook 5 (Combined Backtest) to test all rules together\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# THESIS VERDICT\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ THESIS VERDICT: PRE-MARKET SIGNALS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(df) > 0:\n",
    "    gap_up_pct = (df['gap_pct'] > 0).sum() / len(df) * 100\n",
    "    gap_3pct = (df['gap_pct'] >= 3).sum() / len(df) * 100\n",
    "    avg_vol = df['vol_ratio'].mean()\n",
    "    \n",
    "    print(f\"\\nüìä SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"   Total Day 1's analyzed: {len(df)}\")\n",
    "    print(f\"   Day 1's that gap UP: {gap_up_pct:.0f}%\")\n",
    "    print(f\"   Day 1's with 3%+ gap: {gap_3pct:.0f}%\")\n",
    "    print(f\"   Average volume on Day 1: {avg_vol:.1f}x normal\")\n",
    "    \n",
    "    # Verdict\n",
    "    if gap_up_pct >= 70:\n",
    "        print(f\"\\n‚úÖ THESIS VALIDATED: Day 1's DO gap up in pre-market\")\n",
    "        print(f\"   {gap_up_pct:.0f}% of Day 1's show overnight/pre-market strength\")\n",
    "        \n",
    "        print(f\"\\nüìã ACTIONABLE ENTRY RULES:\")\n",
    "        if gap_3pct >= 50:\n",
    "            print(f\"   1. Look for 3%+ gap on stocks showing Day 0 signals\")\n",
    "        else:\n",
    "            print(f\"   1. Look for any gap UP on stocks showing Day 0 signals\")\n",
    "        print(f\"   2. Confirm with elevated volume ({avg_vol:.0f}x+ normal)\")\n",
    "        print(f\"   3. Enter within first 30 min of market open\")\n",
    "        print(f\"   4. Hold for expected run duration (from Notebook 1)\")\n",
    "        \n",
    "    elif gap_up_pct >= 50:\n",
    "        print(f\"\\n‚ö†Ô∏è THESIS PARTIALLY VALIDATED\")\n",
    "        print(f\"   {gap_up_pct:.0f}% gap up - majority but not overwhelming\")\n",
    "        print(f\"   Use gap as ONE signal, not the ONLY signal\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n‚ùå THESIS KILLED: Day 1's don't reliably gap up\")\n",
    "        print(f\"   Only {gap_up_pct:.0f}% gap up in pre-market\")\n",
    "        print(f\"   Cannot use pre-market as reliable Day 1 signal\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEXT: Run Notebook 5 (Combined Backtest) to test all rules together\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
