{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeac715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your dataset\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "print(f\"Uploaded: {list(uploaded.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install xgboost lightgbm shap -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc3cd0",
   "metadata": {},
   "source": [
    "## Step 2: Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44bb980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('runner_dataset.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nPositive rate: {df['label'].mean():.1%}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns (exclude non-feature columns)\n",
    "exclude_cols = ['ticker', 'move_date', 'actual_gain', 'label', 'price']\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e69016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare features between big moves and normal days\n",
    "pos = df[df['label'] == 1]\n",
    "neg = df[df['label'] == 0]\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Big Move Mean': pos[feature_cols].mean(),\n",
    "    'Normal Mean': neg[feature_cols].mean(),\n",
    "})\n",
    "comparison['Difference'] = comparison['Big Move Mean'] - comparison['Normal Mean']\n",
    "comparison['Diff %'] = (comparison['Difference'] / comparison['Normal Mean'].abs()) * 100\n",
    "\n",
    "# Sort by absolute difference\n",
    "comparison = comparison.sort_values('Diff %', key=abs, ascending=False)\n",
    "\n",
    "print(\"üéØ Top Features by Difference:\")\n",
    "comparison.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top features\n",
    "top_features = comparison.head(10).index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(top_features):\n",
    "    ax = axes[i]\n",
    "    ax.hist(neg[feature], bins=30, alpha=0.5, label='Normal', color='blue')\n",
    "    ax.hist(pos[feature], bins=30, alpha=0.5, label='Big Move', color='red')\n",
    "    ax.set_title(feature)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Feature Distributions: Big Move vs Normal', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1ad0e",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "X = df[feature_cols].fillna(0)\n",
    "y = df['label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"Positive rate in train: {y_train.mean():.1%}\")\n",
    "print(f\"Positive rate in test: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97f468f",
   "metadata": {},
   "source": [
    "## Step 4: Train Models\n",
    "\n",
    "We'll try multiple models and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "\n",
    "# Handle class imbalance\n",
    "scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='auc',\n",
    "    tree_method='gpu_hist'  # Use GPU!\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "y_prob_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nüìä XGBoost Results:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=['Normal', 'Big Move']))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob_xgb):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: LightGBM\n",
    "print(\"Training LightGBM...\")\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    is_unbalance=True,  # Handle imbalance\n",
    "    random_state=42,\n",
    "    device='gpu'  # Use GPU!\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_lgb = lgb_model.predict(X_test_scaled)\n",
    "y_prob_lgb = lgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nüìä LightGBM Results:\")\n",
    "print(classification_report(y_test, y_pred_lgb, target_names=['Normal', 'Big Move']))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob_lgb):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0200d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Ensemble (Average of both)\n",
    "print(\"Creating Ensemble...\")\n",
    "\n",
    "y_prob_ensemble = (y_prob_xgb + y_prob_lgb) / 2\n",
    "y_pred_ensemble = (y_prob_ensemble > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nüìä Ensemble Results:\")\n",
    "print(classification_report(y_test, y_pred_ensemble, target_names=['Normal', 'Big Move']))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob_ensemble):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc2d067",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c501b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from XGBoost\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.barh(importance['feature'][:20], importance['importance'][:20])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('üéØ Top 20 Features for Predicting Big Moves')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ TOP PREDICTIVE FEATURES:\")\n",
    "for _, row in importance.head(15).iterrows():\n",
    "    print(f\"   {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f31c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP values for deeper understanding\n",
    "print(\"Calculating SHAP values (this may take a minute)...\")\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test_scaled[:500])  # Sample for speed\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values, X_test[:500], feature_names=feature_cols, show=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e205ca0",
   "metadata": {},
   "source": [
    "## Step 6: ROC Curve and Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daeb881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, y_prob in [('XGBoost', y_prob_xgb), ('LightGBM', y_prob_lgb), ('Ensemble', y_prob_ensemble)]:\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Big Move Prediction')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold\n",
    "# We want HIGH PRECISION for trading (don't want false positives)\n",
    "\n",
    "print(\"\\nüéØ THRESHOLD ANALYSIS (XGBoost):\")\n",
    "print(f\"{'Threshold':<12} {'Precision':<12} {'Recall':<12} {'F1':<12}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "    y_pred_thresh = (y_prob_xgb >= threshold).astype(int)\n",
    "    \n",
    "    if y_pred_thresh.sum() == 0:\n",
    "        continue\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred_thresh)\n",
    "    recall = recall_score(y_test, y_pred_thresh)\n",
    "    f1 = f1_score(y_test, y_pred_thresh)\n",
    "    \n",
    "    print(f\"{threshold:<12.1f} {precision:<12.3f} {recall:<12.3f} {f1:<12.3f}\")\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\n‚úÖ Recommended threshold: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2decd5e",
   "metadata": {},
   "source": [
    "## Step 7: Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "import pickle\n",
    "\n",
    "# Save XGBoost model\n",
    "with open('runner_model_xgb.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "\n",
    "# Save LightGBM model\n",
    "with open('runner_model_lgb.pkl', 'wb') as f:\n",
    "    pickle.dump(lgb_model, f)\n",
    "\n",
    "# Save scaler\n",
    "with open('runner_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save feature list\n",
    "import json\n",
    "with open('runner_features.json', 'w') as f:\n",
    "    json.dump(feature_cols, f)\n",
    "\n",
    "# Save feature importance\n",
    "importance.to_csv('feature_importance.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Models saved!\")\n",
    "\n",
    "# Download files\n",
    "files.download('runner_model_xgb.pkl')\n",
    "files.download('runner_model_lgb.pkl')\n",
    "files.download('runner_scaler.pkl')\n",
    "files.download('runner_features.json')\n",
    "files.download('feature_importance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e7b0d",
   "metadata": {},
   "source": [
    "## Step 8: Trading Strategy Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate trading with the model\n",
    "print(\"üéÆ BACKTEST SIMULATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use the test set as \"unseen\" data\n",
    "threshold = best_threshold\n",
    "\n",
    "# Get predictions\n",
    "predictions = (y_prob_xgb >= threshold).astype(int)\n",
    "actual_moves = y_test.values\n",
    "actual_gains = df.loc[y_test.index, 'actual_gain'].values\n",
    "\n",
    "# Simulate trades\n",
    "trades_taken = predictions.sum()\n",
    "winning_trades = ((predictions == 1) & (actual_moves == 1)).sum()\n",
    "losing_trades = ((predictions == 1) & (actual_moves == 0)).sum()\n",
    "\n",
    "win_rate = winning_trades / trades_taken if trades_taken > 0 else 0\n",
    "\n",
    "# Calculate returns (simplified)\n",
    "avg_win = actual_gains[(predictions == 1) & (actual_moves == 1)].mean() if winning_trades > 0 else 0\n",
    "avg_loss = -3  # Assume 3% stop loss on losing trades\n",
    "\n",
    "expected_return = (win_rate * avg_win) + ((1 - win_rate) * avg_loss)\n",
    "\n",
    "print(f\"Threshold: {threshold}\")\n",
    "print(f\"Trades taken: {trades_taken}\")\n",
    "print(f\"Winning trades: {winning_trades}\")\n",
    "print(f\"Losing trades: {losing_trades}\")\n",
    "print(f\"Win rate: {win_rate:.1%}\")\n",
    "print(f\"\\nAverage win: +{avg_win:.1f}%\")\n",
    "print(f\"Average loss: {avg_loss}% (assumed stop)\")\n",
    "print(f\"\\nExpected return per trade: {expected_return:.1f}%\")\n",
    "\n",
    "if expected_return > 0:\n",
    "    print(f\"\\nüü¢ POSITIVE EDGE - This strategy has potential!\")\n",
    "else:\n",
    "    print(f\"\\nüî¥ NEGATIVE EDGE - Need to adjust strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43eea4",
   "metadata": {},
   "source": [
    "## üê∫ Findings Summary\n",
    "\n",
    "After training, look at:\n",
    "\n",
    "1. **Top Features** - What predicts big moves?\n",
    "2. **Precision** - How often are predictions correct?\n",
    "3. **Expected Return** - Is there a trading edge?\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "1. Download the saved models\n",
    "2. Copy them to `models/` folder in your repo\n",
    "3. Run `python src/ml/runner_predictor.py scan` to get live predictions\n",
    "\n",
    "**AWOOOO** üê∫"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
