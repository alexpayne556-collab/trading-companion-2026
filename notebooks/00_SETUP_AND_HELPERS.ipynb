{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09b66bf",
   "metadata": {},
   "source": [
    "# ğŸº WOLF PACK RESEARCH - SETUP\n",
    "## Foundation for All Research Notebooks\n",
    "\n",
    "**Purpose:** Load libraries, define universe, create helper functions\n",
    "\n",
    "**Usage:** Run this notebook first, OR copy these cells to the top of each research notebook\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633c689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas display settings\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Matplotlib style\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"âœ… Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === THE REAL UNIVERSE - NOT GENERIC BULLSHIT ===\n",
    "# These are the ACTUAL plays. The ones that moved. The ones moving. The ones about to move.\n",
    "\n",
    "UNIVERSE = {\n",
    "    # MEMORY - MU +20% on analyst upgrades, DRAM squeeze, HBM sold out through 2026\n",
    "    'MEMORY': ['MU', 'INTC', 'AMD', 'NVDA'],\n",
    "    \n",
    "    # AI INFRA - APLD +18% on earnings + $5B deal + short squeeze\n",
    "    'AI_INFRA': ['APLD', 'CORZ', 'WULF', 'HUT', 'CLSK', 'CIFR', 'IREN', 'MARA', 'RIOT'],\n",
    "    \n",
    "    # NUCLEAR - OKLO +17% on Meta deal, VST +11% sympathy. The REAL AI power play.\n",
    "    'NUCLEAR': ['SMR', 'NNE', 'OKLO', 'VST', 'CEG', 'CCJ', 'UEC', 'UUUU', 'LEU'],\n",
    "    \n",
    "    # DEFENSE - Trump 50% budget increase, KTOS (Tyr owns), RCAT drones\n",
    "    'DEFENSE': ['KTOS', 'RCAT', 'PLTR', 'BBAI', 'AVAV', 'LMT', 'RTX'],\n",
    "    \n",
    "    # SPACE - RKLB $805M contract, space exec order Dec 2025\n",
    "    'SPACE': ['RKLB', 'LUNR', 'RDW', 'ASTS', 'SPIR', 'BKSY'],\n",
    "    \n",
    "    # LIDAR / AV - AEVA +51% week, led whole sector on NVIDIA partnership\n",
    "    'LIDAR_AV': ['AEVA', 'OUST', 'INVZ', 'LAZR', 'MVIS'],\n",
    "    \n",
    "    # AI SOFTWARE - SOUN CES catalyst, voice AI is the interface\n",
    "    'AI_SOFTWARE': ['SOUN', 'AI', 'PATH', 'UPST'],\n",
    "    \n",
    "    # QUANTUM - Extreme volatility, RGTI +1000% then crashed. Pattern testing.\n",
    "    'QUANTUM': ['IONQ', 'RGTI', 'QBTS', 'QUBT'],\n",
    "    \n",
    "    # FINTECH - HOOD 13 insider transactions! SOFI profitable with bank charter\n",
    "    'FINTECH': ['SOFI', 'HOOD', 'AFRM', 'NU'],\n",
    "    \n",
    "    # BIOTECH - NTLA (Tyr owns) JP Morgan conference this week\n",
    "    'BIOTECH': ['NTLA', 'CRSP', 'BEAM', 'EDIT', 'RXRX', 'DNA'],\n",
    "    \n",
    "    # CANNABIS - TLRY (Tyr owns) just beat earnings +7% AH\n",
    "    'CANNABIS': ['TLRY', 'CGC', 'SNDL'],\n",
    "    \n",
    "    # EMERGING - Second order plays, next runners before they run\n",
    "    'EMERGING': ['SKYT', 'KULR', 'GEVO', 'PLUG', 'BE', 'FCEL'],\n",
    "}\n",
    "\n",
    "# Build full ticker list\n",
    "ALL_TICKERS = list(set([t for sector in UNIVERSE.values() for t in sector]))\n",
    "\n",
    "# Reverse lookup - which sector is each ticker in\n",
    "TICKER_TO_SECTOR = {}\n",
    "for sector, tickers in UNIVERSE.items():\n",
    "    for t in tickers:\n",
    "        TICKER_TO_SECTOR[t] = sector\n",
    "\n",
    "# The big winners we need to reverse engineer\n",
    "BIG_WINNERS = {\n",
    "    'MU': {'move': '+20%', 'when': 'Week 1 Jan 2026', 'why': 'Analyst upgrades, DRAM squeeze'},\n",
    "    'APLD': {'move': '+18%', 'when': 'Jan 7-10', 'why': '$5B hyperscaler deal + earnings + short squeeze'},\n",
    "    'OKLO': {'move': '+17%', 'when': 'Jan 9', 'why': 'Meta nuclear deal announced'},\n",
    "    'VST': {'move': '+11%', 'when': 'Jan 9', 'why': 'Sympathy to OKLO/Meta deal'},\n",
    "    'AEVA': {'move': '+51%', 'when': 'Week of Jan 6', 'why': 'NVIDIA partnership, CES'},\n",
    "    'TLRY': {'move': '+7% AH', 'when': 'Jan 8', 'why': 'Earnings beat $218M revenue'},\n",
    "}\n",
    "\n",
    "# Current holdings (Tyr's positions)\n",
    "CURRENT_HOLDINGS = ['APLD', 'KTOS', 'TLRY', 'NTLA']\n",
    "\n",
    "print(f\"ğŸº REAL UNIVERSE LOADED: {len(ALL_TICKERS)} tickers across {len(UNIVERSE)} sectors\")\n",
    "print()\n",
    "print(\"SECTORS:\")\n",
    "for sector, tickers in UNIVERSE.items():\n",
    "    print(f\"  {sector}: {', '.join(tickers)}\")\n",
    "print()\n",
    "print(\"ğŸ“ˆ BIG WINNERS TO REVERSE ENGINEER:\")\n",
    "for ticker, data in BIG_WINNERS.items():\n",
    "    print(f\"  {ticker}: {data['move']} - {data['why']}\")\n",
    "print()\n",
    "print(f\"ğŸ’¼ CURRENT HOLDINGS: {', '.join(CURRENT_HOLDINGS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8086f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HELPER FUNCTIONS - THE GOOD STUFF ===\n",
    "\n",
    "def get_data(ticker, period='3mo'):\n",
    "    \"\"\"Pull historical data - our raw material\"\"\"\n",
    "    try:\n",
    "        df = yf.Ticker(ticker).history(period=period)\n",
    "        if len(df) > 0:\n",
    "            df['ticker'] = ticker\n",
    "            df['sector'] = TICKER_TO_SECTOR.get(ticker, 'UNKNOWN')\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Error loading {ticker}: {e}\")\n",
    "    return None\n",
    "\n",
    "def get_all_data(tickers=None, period='3mo', verbose=True):\n",
    "    \"\"\"Get data for entire universe or subset\"\"\"\n",
    "    if tickers is None:\n",
    "        tickers = ALL_TICKERS\n",
    "    \n",
    "    frames = []\n",
    "    if verbose:\n",
    "        print(f\"Loading {len(tickers)} tickers...\")\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        df = get_data(ticker, period)\n",
    "        if df is not None and len(df) > 20:\n",
    "            frames.append(df)\n",
    "        if verbose:\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\" Done! {len(frames)}/{len(tickers)} loaded\")\n",
    "    \n",
    "    if len(frames) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return pd.concat(frames)\n",
    "\n",
    "def rsi(prices, period=14):\n",
    "    \"\"\"Calculate RSI indicator\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def add_features(df):\n",
    "    \"\"\"Add ALL the indicators we might care about\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic returns\n",
    "    df['daily_ret'] = df['Close'].pct_change()\n",
    "    df['intraday_ret'] = (df['Close'] - df['Open']) / df['Open']\n",
    "    \n",
    "    # Volume analysis\n",
    "    df['vol_avg_20'] = df['Volume'].rolling(20).mean()\n",
    "    df['vol_ratio'] = df['Volume'] / df['vol_avg_20']\n",
    "    df['vol_trend'] = df['Volume'].rolling(5).mean() / df['Volume'].rolling(20).mean()\n",
    "    \n",
    "    # RSI\n",
    "    df['rsi'] = rsi(df['Close'])\n",
    "    \n",
    "    # Momentum - past performance\n",
    "    df['ret_1d_past'] = df['Close'] / df['Close'].shift(1) - 1\n",
    "    df['ret_3d_past'] = df['Close'] / df['Close'].shift(3) - 1\n",
    "    df['ret_5d_past'] = df['Close'] / df['Close'].shift(5) - 1\n",
    "    df['ret_10d_past'] = df['Close'] / df['Close'].shift(10) - 1\n",
    "    df['ret_20d_past'] = df['Close'] / df['Close'].shift(20) - 1\n",
    "    \n",
    "    # Distance from highs\n",
    "    df['high_5d'] = df['High'].rolling(5).max()\n",
    "    df['high_20d'] = df['High'].rolling(20).max()\n",
    "    df['high_60d'] = df['High'].rolling(60).max()\n",
    "    df['dist_from_5d_high'] = df['Close'] / df['high_5d'] - 1\n",
    "    df['dist_from_20d_high'] = df['Close'] / df['high_20d'] - 1\n",
    "    df['dist_from_60d_high'] = df['Close'] / df['high_60d'] - 1\n",
    "    \n",
    "    # Distance from lows\n",
    "    df['low_20d'] = df['Low'].rolling(20).min()\n",
    "    df['dist_from_20d_low'] = df['Close'] / df['low_20d'] - 1\n",
    "    \n",
    "    # Volatility\n",
    "    df['volatility_10d'] = df['daily_ret'].rolling(10).std()\n",
    "    df['volatility_20d'] = df['daily_ret'].rolling(20).std()\n",
    "    \n",
    "    # Gap analysis\n",
    "    df['gap'] = df['Open'] / df['Close'].shift(1) - 1\n",
    "    \n",
    "    # Range\n",
    "    df['daily_range'] = (df['High'] - df['Low']) / df['Close']\n",
    "    df['range_avg'] = df['daily_range'].rolling(10).mean()\n",
    "    \n",
    "    # Moving averages\n",
    "    df['sma_10'] = df['Close'].rolling(10).mean()\n",
    "    df['sma_20'] = df['Close'].rolling(20).mean()\n",
    "    df['sma_50'] = df['Close'].rolling(50).mean()\n",
    "    df['above_sma20'] = df['Close'] > df['sma_20']\n",
    "    df['dist_from_sma20'] = df['Close'] / df['sma_20'] - 1\n",
    "    \n",
    "    # Day of week\n",
    "    df['dow'] = pd.to_datetime(df.index).dayofweek\n",
    "    df['is_monday'] = df['dow'] == 0\n",
    "    df['is_friday'] = df['dow'] == 4\n",
    "    \n",
    "    # Forward returns (what we're trying to predict)\n",
    "    df['fwd_1d'] = df['Close'].shift(-1) / df['Close'] - 1\n",
    "    df['fwd_3d'] = df['Close'].shift(-3) / df['Close'] - 1\n",
    "    df['fwd_5d'] = df['Close'].shift(-5) / df['Close'] - 1\n",
    "    df['fwd_10d'] = df['Close'].shift(-10) / df['Close'] - 1\n",
    "    \n",
    "    # Is this a big move day?\n",
    "    df['is_big_up'] = df['daily_ret'] > 0.10\n",
    "    df['is_big_down'] = df['daily_ret'] < -0.10\n",
    "    \n",
    "    return df\n",
    "\n",
    "def print_stats(series, label=\"\"):\n",
    "    \"\"\"Print summary statistics for a series\"\"\"\n",
    "    clean = series.dropna()\n",
    "    if len(clean) == 0:\n",
    "        print(f\"{label}: No data\")\n",
    "        return\n",
    "    \n",
    "    print(f\"{label}:\")\n",
    "    print(f\"  Count: {len(clean)}\")\n",
    "    print(f\"  Mean: {clean.mean()*100:+.2f}%\")\n",
    "    print(f\"  Median: {clean.median()*100:+.2f}%\")\n",
    "    print(f\"  Win Rate: {(clean > 0).mean()*100:.1f}%\")\n",
    "    print(f\"  Best: {clean.max()*100:+.2f}%\")\n",
    "    print(f\"  Worst: {clean.min()*100:+.2f}%\")\n",
    "\n",
    "def load_master():\n",
    "    \"\"\"Load entire universe with all features\"\"\"\n",
    "    data = get_all_data()\n",
    "    frames = []\n",
    "    for ticker in data['ticker'].unique():\n",
    "        df = data[data['ticker'] == ticker].copy()\n",
    "        df = add_features(df)\n",
    "        frames.append(df)\n",
    "    return pd.concat(frames)\n",
    "\n",
    "print(\"âœ… Helper functions loaded\")\n",
    "print()\n",
    "print(\"QUICK FUNCTIONS:\")\n",
    "print(\"  get_data('MU', '3mo')        - Get single ticker\")\n",
    "print(\"  get_all_data()               - Get entire universe\")\n",
    "print(\"  add_features(df)             - Add all indicators\")\n",
    "print(\"  load_master()                - Load everything with features\")\n",
    "print(\"  print_stats(series, 'label') - Print return stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD ALL DATA ===\n",
    "print(\"ğŸº Loading entire universe...\")\n",
    "print(\"This takes 1-2 minutes. Be patient.\\n\")\n",
    "\n",
    "all_frames = []\n",
    "failed = []\n",
    "\n",
    "for ticker in ALL_TICKERS:\n",
    "    try:\n",
    "        df = yf.Ticker(ticker).history(period='3mo')\n",
    "        if len(df) > 20:\n",
    "            df['ticker'] = ticker\n",
    "            df['sector'] = TICKER_TO_SECTOR.get(ticker, 'UNKNOWN')\n",
    "            df = add_features(df)\n",
    "            all_frames.append(df)\n",
    "            print(\"âœ“\", end=\"\", flush=True)\n",
    "        else:\n",
    "            failed.append(ticker)\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "    except:\n",
    "        failed.append(ticker)\n",
    "        print(\"X\", end=\"\", flush=True)\n",
    "\n",
    "master = pd.concat(all_frames)\n",
    "print(f\"\\n\\nâœ… LOADED {len(all_frames)} tickers, {len(master)} total rows\")\n",
    "print(f\"Date range: {master.index.min().date()} to {master.index.max().date()}\")\n",
    "if failed:\n",
    "    print(f\"âš ï¸  Failed to load: {', '.join(failed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d986f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸº SETUP COMPLETE\n",
    "\n",
    "You now have:\n",
    "- âœ… All libraries imported\n",
    "- âœ… Universe defined (50+ tickers)\n",
    "- âœ… Helper functions ready\n",
    "- âœ… Test data loaded\n",
    "\n",
    "**Ready to hunt.**\n",
    "\n",
    "Next: Run a research notebook (RESEARCH_01, RESEARCH_02, etc.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 1: RSI - DOES IT ACTUALLY WORK ON OUR VOLATILE STOCKS?\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 1: RSI ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# RSI < 30 (Oversold)\n",
    "oversold = master[master['rsi'] < 30]\n",
    "print(f\"\\nğŸ“Š RSI < 30 (Oversold): {len(oversold)} events\")\n",
    "print(f\"  1-day forward:  avg {oversold['fwd_1d'].mean()*100:+.2f}%, win rate {(oversold['fwd_1d']>0).mean()*100:.1f}%\")\n",
    "print(f\"  5-day forward:  avg {oversold['fwd_5d'].mean()*100:+.2f}%, win rate {(oversold['fwd_5d']>0).mean()*100:.1f}%\")\n",
    "print(f\"  10-day forward: avg {oversold['fwd_10d'].mean()*100:+.2f}%, win rate {(oversold['fwd_10d']>0).mean()*100:.1f}%\")\n",
    "\n",
    "# RSI > 70 (Overbought)\n",
    "overbought = master[master['rsi'] > 70]\n",
    "print(f\"\\nğŸ“Š RSI > 70 (Overbought): {len(overbought)} events\")\n",
    "print(f\"  1-day forward:  avg {overbought['fwd_1d'].mean()*100:+.2f}%, win rate {(overbought['fwd_1d']>0).mean()*100:.1f}%\")\n",
    "print(f\"  5-day forward:  avg {overbought['fwd_5d'].mean()*100:+.2f}%, win rate {(overbought['fwd_5d']>0).mean()*100:.1f}%\")\n",
    "print(f\"  10-day forward: avg {overbought['fwd_10d'].mean()*100:+.2f}%, win rate {(overbought['fwd_10d']>0).mean()*100:.1f}%\")\n",
    "\n",
    "# BASELINE comparison\n",
    "baseline = master['fwd_5d'].dropna()\n",
    "print(f\"\\nğŸ“Š BASELINE (Any Random Day): {len(baseline)} events\")\n",
    "print(f\"  5-day forward:  avg {baseline.mean()*100:+.2f}%, win rate {(baseline>0).mean()*100:.1f}%\")\n",
    "\n",
    "# VERDICT\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "rsi_edge = oversold['fwd_5d'].mean() - baseline.mean()\n",
    "print(f\"ğŸ’¡ RSI < 30 EDGE over baseline: {rsi_edge*100:+.2f}%\")\n",
    "if rsi_edge > 0.01:\n",
    "    print(\"   âœ… RSI oversold shows POSITIVE edge\")\n",
    "else:\n",
    "    print(\"   âŒ RSI oversold does NOT beat random\")\n",
    "\n",
    "ob_edge = overbought['fwd_5d'].mean() - baseline.mean()\n",
    "print(f\"ğŸ’¡ RSI > 70 vs baseline: {ob_edge*100:+.2f}%\")\n",
    "if ob_edge > 0:\n",
    "    print(\"   âš ï¸ Overbought stocks KEEP GOING UP - don't sell just because RSI high!\")\n",
    "else:\n",
    "    print(\"   âœ… Overbought = valid sell signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d871f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 2: VOLUME SPIKES - WHAT DO THEY MEAN?\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 2: VOLUME SPIKE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Volume > 2x average\n",
    "vol_spike = master[master['vol_ratio'] > 2].copy()\n",
    "vol_spike_up = vol_spike[vol_spike['daily_ret'] > 0]\n",
    "vol_spike_down = vol_spike[vol_spike['daily_ret'] < 0]\n",
    "\n",
    "print(f\"\\nğŸ“Š Volume > 2x Average: {len(vol_spike)} events\")\n",
    "print(f\"  UP days with volume spike: {len(vol_spike_up)}\")\n",
    "print(f\"  DOWN days with volume spike: {len(vol_spike_down)}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š After UP day with volume spike:\")\n",
    "print(f\"  5-day forward: avg {vol_spike_up['fwd_5d'].mean()*100:+.2f}%, win rate {(vol_spike_up['fwd_5d']>0).mean()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nğŸ“Š After DOWN day with volume spike:\")\n",
    "print(f\"  5-day forward: avg {vol_spike_down['fwd_5d'].mean()*100:+.2f}%, win rate {(vol_spike_down['fwd_5d']>0).mean()*100:.1f}%\")\n",
    "\n",
    "# Test different magnitudes\n",
    "print(\"\\nğŸ“Š Volume Magnitude Testing:\")\n",
    "for mult in [1.5, 2.0, 3.0, 5.0]:\n",
    "    subset = master[master['vol_ratio'] > mult]\n",
    "    if len(subset) > 10:\n",
    "        avg = subset['fwd_5d'].mean()*100\n",
    "        win = (subset['fwd_5d']>0).mean()*100\n",
    "        print(f\"  Vol > {mult}x: n={len(subset):4d}, 5d return {avg:+.2f}%, win {win:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ VOLUME INSIGHTS:\")\n",
    "if vol_spike_up['fwd_5d'].mean() > baseline.mean():\n",
    "    print(\"   âœ… UP + Volume = momentum continues\")\n",
    "else:\n",
    "    print(\"   âŒ UP + Volume = exhaustion, fade it\")\n",
    "    \n",
    "if vol_spike_down['fwd_5d'].mean() > 0:\n",
    "    print(\"   âœ… DOWN + Volume = capitulation, BUY signal\")\n",
    "else:\n",
    "    print(\"   âŒ DOWN + Volume = breakdown, avoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e9a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 3: MOMENTUM - CHASE OR FADE?\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 3: MOMENTUM ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š After stock UP X% in past 5 days, what happens next 5 days?\")\n",
    "print(\"-\"*70)\n",
    "for threshold in [5, 10, 15, 20, 30]:\n",
    "    subset = master[master['ret_5d_past'] > threshold/100]\n",
    "    if len(subset) > 10:\n",
    "        avg = subset['fwd_5d'].mean()*100\n",
    "        win = (subset['fwd_5d']>0).mean()*100\n",
    "        print(f\"  Past 5d > +{threshold}%: n={len(subset):4d}, next 5d {avg:+.2f}%, win {win:.1f}%\")\n",
    "\n",
    "print(\"\\nğŸ“Š After stock DOWN X% in past 5 days:\")\n",
    "print(\"-\"*70)\n",
    "for threshold in [-5, -10, -15, -20, -30]:\n",
    "    subset = master[master['ret_5d_past'] < threshold/100]\n",
    "    if len(subset) > 10:\n",
    "        avg = subset['fwd_5d'].mean()*100\n",
    "        win = (subset['fwd_5d']>0).mean()*100\n",
    "        print(f\"  Past 5d < {threshold}%: n={len(subset):4d}, next 5d {avg:+.2f}%, win {win:.1f}%\")\n",
    "\n",
    "# Find the sweet spot\n",
    "print(\"\\nğŸ“Š MOMENTUM SWEET SPOT:\")\n",
    "print(\"-\"*70)\n",
    "ranges = [\n",
    "    (-30, -20, \"Deep dip (-30 to -20%)\"),\n",
    "    (-20, -10, \"Moderate dip (-20 to -10%)\"),\n",
    "    (-10, 0, \"Slight dip (-10 to 0%)\"),\n",
    "    (0, 10, \"Slight up (0 to +10%)\"),\n",
    "    (10, 20, \"Moderate run (+10 to +20%)\"),\n",
    "    (20, 30, \"Hot (+20 to +30%)\"),\n",
    "    (30, 100, \"On fire (+30%+)\"),\n",
    "]\n",
    "for low, high, label in ranges:\n",
    "    subset = master[(master['ret_5d_past'] > low/100) & (master['ret_5d_past'] <= high/100)]\n",
    "    if len(subset) > 20:\n",
    "        avg = subset['fwd_5d'].mean()*100\n",
    "        win = (subset['fwd_5d']>0).mean()*100\n",
    "        print(f\"  {label:25s}: n={len(subset):4d}, next 5d {avg:+.2f}%, win {win:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ MOMENTUM INSIGHTS:\")\n",
    "hot_returns = master[master['ret_5d_past'] > 0.20]['fwd_5d'].mean()\n",
    "dip_returns = master[(master['ret_5d_past'] < -0.10) & (master['ret_5d_past'] > -0.20)]['fwd_5d'].mean()\n",
    "if hot_returns > dip_returns:\n",
    "    print(\"   âœ… CHASE MOMENTUM - Hot stocks keep running\")\n",
    "else:\n",
    "    print(\"   âœ… BUY DIPS - Pullbacks outperform chasing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df7132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 4: SECTOR CORRELATION - DO SYMPATHY PLAYS WORK?\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 4: SECTOR CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def test_sector_correlation(sector_name):\n",
    "    \"\"\"Test if stocks in a sector move together\"\"\"\n",
    "    tickers = UNIVERSE.get(sector_name, [])\n",
    "    sector_data = master[master['sector'] == sector_name].copy()\n",
    "    \n",
    "    if len(sector_data) < 100:\n",
    "        return None\n",
    "    \n",
    "    # Pivot to get returns by ticker\n",
    "    try:\n",
    "        pivoted = sector_data.pivot_table(\n",
    "            values='daily_ret',\n",
    "            index=sector_data.index.date,\n",
    "            columns='ticker'\n",
    "        )\n",
    "        \n",
    "        corr = pivoted.corr()\n",
    "        avg_corr = corr.values[np.triu_indices_from(corr.values, 1)].mean()\n",
    "        \n",
    "        return {'sector': sector_name, 'avg_correlation': avg_corr, 'matrix': corr}\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"\\nğŸ“Š SECTOR CORRELATIONS (Do they move together?)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "sector_corrs = {}\n",
    "for sector in UNIVERSE.keys():\n",
    "    result = test_sector_correlation(sector)\n",
    "    if result:\n",
    "        sector_corrs[sector] = result['avg_correlation']\n",
    "        print(f\"  {sector:15s}: avg correlation {result['avg_correlation']:.2f}\")\n",
    "\n",
    "# Find highest correlation sectors (best for sympathy plays)\n",
    "if sector_corrs:\n",
    "    sorted_sectors = sorted(sector_corrs.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nğŸ’¡ SYMPATHY PLAY RANKING (highest correlation = best for sympathy):\")\n",
    "    for sector, corr in sorted_sectors[:5]:\n",
    "        print(f\"   {sector}: {corr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1735263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 5: REVERSE ENGINEER THE BIG WINNERS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 5: WHAT DO +20% MOVES LOOK LIKE BEFORE THEY HAPPEN?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find all +20% moves in 10 days\n",
    "winners = master[master['fwd_10d'] > 0.20].copy()\n",
    "\n",
    "print(f\"\\nğŸ“Š Found {len(winners)} instances of +20%+ in 10 days\")\n",
    "\n",
    "print(\"\\nğŸ“Š WINNER PROFILE (what they looked like BEFORE the move):\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"  Average RSI:              {winners['rsi'].mean():.1f} (vs {master['rsi'].mean():.1f} overall)\")\n",
    "print(f\"  Average distance from high: {winners['dist_from_20d_high'].mean()*100:.1f}% (vs {master['dist_from_20d_high'].mean()*100:.1f}%)\")\n",
    "print(f\"  Average past 5d momentum:   {winners['ret_5d_past'].mean()*100:+.1f}% (vs {master['ret_5d_past'].mean()*100:+.1f}%)\")\n",
    "print(f\"  Average volume ratio:       {winners['vol_ratio'].mean():.2f}x (vs {master['vol_ratio'].mean():.2f}x)\")\n",
    "print(f\"  Average volatility:         {winners['volatility_10d'].mean()*100:.2f}% (vs {master['volatility_10d'].mean()*100:.2f}%)\")\n",
    "\n",
    "# What % of winners had these characteristics?\n",
    "print(\"\\nğŸ“Š WINNER CHARACTERISTICS (% that had these traits):\")\n",
    "print(\"-\"*70)\n",
    "print(f\"  RSI < 40:               {(winners['rsi'] < 40).mean()*100:.1f}%\")\n",
    "print(f\"  RSI < 50:               {(winners['rsi'] < 50).mean()*100:.1f}%\")\n",
    "print(f\"  RSI > 60:               {(winners['rsi'] > 60).mean()*100:.1f}%\")\n",
    "print(f\"  Down 10%+ from high:    {(winners['dist_from_20d_high'] < -0.10).mean()*100:.1f}%\")\n",
    "print(f\"  Down 20%+ from high:    {(winners['dist_from_20d_high'] < -0.20).mean()*100:.1f}%\")\n",
    "print(f\"  Past 5d was positive:   {(winners['ret_5d_past'] > 0).mean()*100:.1f}%\")\n",
    "print(f\"  Past 5d was > +10%:     {(winners['ret_5d_past'] > 0.10).mean()*100:.1f}%\")\n",
    "print(f\"  Volume > 1.5x average:  {(winners['vol_ratio'] > 1.5).mean()*100:.1f}%\")\n",
    "print(f\"  Volume > 2x average:    {(winners['vol_ratio'] > 2).mean()*100:.1f}%\")\n",
    "\n",
    "# Which tickers produced the most winners?\n",
    "print(\"\\nğŸ“Š WHICH TICKERS PRODUCED THE MOST +20% MOVES:\")\n",
    "print(\"-\"*70)\n",
    "winner_counts = winners.groupby('ticker').size().sort_values(ascending=False)\n",
    "for ticker, count in winner_counts.head(10).items():\n",
    "    print(f\"  {ticker}: {count} times\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ WINNER PROFILE INSIGHT:\")\n",
    "if winners['ret_5d_past'].mean() > 0:\n",
    "    print(\"   Winners had POSITIVE momentum going in - ride momentum!\")\n",
    "else:\n",
    "    print(\"   Winners came from PULLBACKS - buy dips!\")\n",
    "if winners['rsi'].mean() < 50:\n",
    "    print(\"   Winners had LOW RSI - oversold was the setup!\")\n",
    "else:\n",
    "    print(\"   Winners had HIGH RSI - momentum, not oversold!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddaadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 6: DAY OF WEEK - IS MONDAY ACTUALLY BETTER?\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 6: DAY OF WEEK ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "dow_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "\n",
    "print(\"\\nğŸ“Š Returns by Day of Week:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Day':<12} {'Avg Return':<15} {'Win Rate':<12} {'Volatility':<12} {'Count'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for dow in range(5):\n",
    "    subset = master[master['dow'] == dow]\n",
    "    avg = subset['daily_ret'].mean()*100\n",
    "    win = (subset['daily_ret'] > 0).mean()*100\n",
    "    vol = subset['daily_ret'].std()*100\n",
    "    count = len(subset)\n",
    "    print(f\"{dow_names[dow]:<12} {avg:+.3f}%        {win:.1f}%        {vol:.2f}%        {count}\")\n",
    "\n",
    "# Find best day\n",
    "dow_returns = master.groupby('dow')['daily_ret'].mean()\n",
    "best_dow = dow_returns.idxmax()\n",
    "worst_dow = dow_returns.idxmin()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ğŸ’¡ BEST DAY: {dow_names[best_dow]} ({dow_returns[best_dow]*100:+.3f}%)\")\n",
    "print(f\"ğŸ’¡ WORST DAY: {dow_names[worst_dow]} ({dow_returns[worst_dow]*100:+.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 7: GAP ANALYSIS - FADE OR FOLLOW?\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 7: GAP ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š Gap Up Analysis (Open > Previous Close):\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for thresh in [0.03, 0.05, 0.10, 0.15]:\n",
    "    gap_ups = master[master['gap'] > thresh]\n",
    "    if len(gap_ups) > 5:\n",
    "        # What happens by end of day? (intraday)\n",
    "        intraday = gap_ups['intraday_ret'].mean()*100\n",
    "        # What happens next day?\n",
    "        next_day = gap_ups['fwd_1d'].mean()*100\n",
    "        next_5d = gap_ups['fwd_5d'].mean()*100\n",
    "        \n",
    "        print(f\"  Gap up > {thresh*100:.0f}%: n={len(gap_ups):4d}\")\n",
    "        print(f\"    Same day (intraday):  {intraday:+.2f}% (fade = negative)\")\n",
    "        print(f\"    Next day:             {next_day:+.2f}%\")\n",
    "        print(f\"    Next 5 days:          {next_5d:+.2f}%\")\n",
    "\n",
    "print(\"\\nğŸ“Š Gap Down Analysis:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for thresh in [-0.03, -0.05, -0.10, -0.15]:\n",
    "    gap_downs = master[master['gap'] < thresh]\n",
    "    if len(gap_downs) > 5:\n",
    "        intraday = gap_downs['intraday_ret'].mean()*100\n",
    "        next_day = gap_downs['fwd_1d'].mean()*100\n",
    "        next_5d = gap_downs['fwd_5d'].mean()*100\n",
    "        \n",
    "        print(f\"  Gap down < {thresh*100:.0f}%: n={len(gap_downs):4d}\")\n",
    "        print(f\"    Same day (intraday):  {intraday:+.2f}% (bounce = positive)\")\n",
    "        print(f\"    Next day:             {next_day:+.2f}%\")\n",
    "        print(f\"    Next 5 days:          {next_5d:+.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "gap_up_5pct = master[master['gap'] > 0.05]['fwd_5d'].mean()\n",
    "gap_down_5pct = master[master['gap'] < -0.05]['fwd_5d'].mean()\n",
    "print(\"ğŸ’¡ GAP INSIGHTS:\")\n",
    "if gap_up_5pct > 0:\n",
    "    print(\"   âœ… Gap ups CONTINUE - don't fade, follow!\")\n",
    "else:\n",
    "    print(\"   âœ… Gap ups FADE - take profits on gap ups\")\n",
    "if gap_down_5pct > 0:\n",
    "    print(\"   âœ… Gap downs BOUNCE - buy the panic!\")\n",
    "else:\n",
    "    print(\"   âŒ Gap downs CONTINUE - avoid catching falling knives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 8: PULLBACK SWEET SPOT - HOW FAR FROM HIGH IS BEST?\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 8: DISTANCE FROM HIGH ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š Where should we buy? (Distance from 20-day high)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "ranges = [\n",
    "    (0, -0.05, \"At highs (0 to -5%)\"),\n",
    "    (-0.05, -0.10, \"Slight dip (-5% to -10%)\"),\n",
    "    (-0.10, -0.20, \"Pullback (-10% to -20%)\"),\n",
    "    (-0.20, -0.30, \"Correction (-20% to -30%)\"),\n",
    "    (-0.30, -0.40, \"Deep pullback (-30% to -40%)\"),\n",
    "    (-0.40, -0.50, \"Crash (-40% to -50%)\"),\n",
    "    (-0.50, -1.0, \"Destroyed (-50%+)\"),\n",
    "]\n",
    "\n",
    "best_zone = None\n",
    "best_return = -999\n",
    "\n",
    "for high_bound, low_bound, label in ranges:\n",
    "    subset = master[(master['dist_from_20d_high'] <= high_bound) & \n",
    "                    (master['dist_from_20d_high'] > low_bound)]\n",
    "    if len(subset) > 20:\n",
    "        avg = subset['fwd_5d'].mean()*100\n",
    "        win = (subset['fwd_5d']>0).mean()*100\n",
    "        print(f\"  {label:25s}: n={len(subset):4d}, 5d return {avg:+.2f}%, win {win:.1f}%\")\n",
    "        \n",
    "        if avg > best_return:\n",
    "            best_return = avg\n",
    "            best_zone = label\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ğŸ’¡ BEST BUY ZONE: {best_zone}\")\n",
    "print(f\"   Expected 5-day return: {best_return:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846b1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 9: COMBINED SIGNALS - STACKING EDGES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 9: COMBINED SIGNALS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def score_day(row):\n",
    "    \"\"\"Score each day based on multiple signals\"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # RSI oversold\n",
    "    if row['rsi'] < 40:\n",
    "        score += 1\n",
    "    if row['rsi'] < 30:\n",
    "        score += 1\n",
    "    \n",
    "    # Pullback from high\n",
    "    if row['dist_from_20d_high'] < -0.10:\n",
    "        score += 1\n",
    "    if row['dist_from_20d_high'] < -0.20:\n",
    "        score += 1\n",
    "        \n",
    "    # Volume confirmation\n",
    "    if row['vol_ratio'] > 1.5:\n",
    "        score += 1\n",
    "    if row['vol_ratio'] > 2.0:\n",
    "        score += 1\n",
    "        \n",
    "    # Positive momentum starting (but not extended)\n",
    "    if row['ret_5d_past'] > 0 and row['ret_5d_past'] < 0.15:\n",
    "        score += 1\n",
    "    \n",
    "    # Above moving average (trend)\n",
    "    if row['above_sma20']:\n",
    "        score += 1\n",
    "    \n",
    "    return score\n",
    "\n",
    "master['signal_score'] = master.apply(score_day, axis=1)\n",
    "\n",
    "print(\"\\nğŸ“Š Signal Score vs Forward Returns:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Score':<8} {'Count':<10} {'5d Return':<15} {'Win Rate'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for score in range(0, 9):\n",
    "    subset = master[master['signal_score'] == score]\n",
    "    if len(subset) > 20:\n",
    "        avg = subset['fwd_5d'].mean()*100\n",
    "        win = (subset['fwd_5d']>0).mean()*100\n",
    "        print(f\"{score:<8} {len(subset):<10} {avg:+.2f}%          {win:.1f}%\")\n",
    "\n",
    "# Test high score vs low score\n",
    "high_score = master[master['signal_score'] >= 4]\n",
    "low_score = master[master['signal_score'] <= 1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ STACKING SIGNALS:\")\n",
    "print(f\"   High score (4+): {high_score['fwd_5d'].mean()*100:+.2f}%, win rate {(high_score['fwd_5d']>0).mean()*100:.1f}% (n={len(high_score)})\")\n",
    "print(f\"   Low score (0-1): {low_score['fwd_5d'].mean()*100:+.2f}%, win rate {(low_score['fwd_5d']>0).mean()*100:.1f}% (n={len(low_score)})\")\n",
    "edge = high_score['fwd_5d'].mean() - low_score['fwd_5d'].mean()\n",
    "print(f\"   EDGE FROM STACKING: {edge*100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 10: PATTERNS HUMANS MIGHT MISS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 10: HIDDEN PATTERNS - What humans miss\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# PATTERN 1: Volatility Contraction -> Expansion\n",
    "print(\"\\nğŸ“Š PATTERN 1: Volatility Contraction (calm before storm)\")\n",
    "print(\"-\"*70)\n",
    "master['vol_contracting'] = master['volatility_10d'] < master['volatility_20d'] * 0.7\n",
    "contracted = master[master['vol_contracting']]\n",
    "print(f\"  When volatility contracts (10d vol < 70% of 20d vol):\")\n",
    "print(f\"    Count: {len(contracted)}\")\n",
    "print(f\"    Next 5d return: {contracted['fwd_5d'].mean()*100:+.2f}%\")\n",
    "print(f\"    Win rate: {(contracted['fwd_5d']>0).mean()*100:.1f}%\")\n",
    "\n",
    "# PATTERN 2: Consecutive Days\n",
    "print(\"\\nğŸ“Š PATTERN 2: After Consecutive Up/Down Days\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "def count_streak(df):\n",
    "    streaks = []\n",
    "    current_streak = 0\n",
    "    for ret in df['daily_ret']:\n",
    "        if pd.isna(ret):\n",
    "            streaks.append(0)\n",
    "        elif ret > 0:\n",
    "            current_streak = max(1, current_streak + 1) if current_streak > 0 else 1\n",
    "            streaks.append(current_streak)\n",
    "        else:\n",
    "            current_streak = min(-1, current_streak - 1) if current_streak < 0 else -1\n",
    "            streaks.append(current_streak)\n",
    "    return streaks\n",
    "\n",
    "# Apply to each ticker\n",
    "master['streak'] = master.groupby('ticker').apply(\n",
    "    lambda x: pd.Series(count_streak(x), index=x.index)\n",
    ").values.flatten() if 'ticker' in master.columns else 0\n",
    "\n",
    "three_up = master[master['streak'] >= 3]\n",
    "three_down = master[master['streak'] <= -3]\n",
    "\n",
    "print(f\"  After 3+ green days: n={len(three_up)}, next day {three_up['fwd_1d'].mean()*100:+.2f}%\")\n",
    "print(f\"  After 3+ red days: n={len(three_down)}, next day {three_down['fwd_1d'].mean()*100:+.2f}%\")\n",
    "\n",
    "# PATTERN 3: Volume Exhaustion (Big move on declining volume)\n",
    "print(\"\\nğŸ“Š PATTERN 3: Volume Exhaustion (move without volume confirmation)\")\n",
    "print(\"-\"*70)\n",
    "exhaustion = master[(master['ret_5d_past'] > 0.15) & (master['vol_trend'] < 0.8)]\n",
    "confirmed = master[(master['ret_5d_past'] > 0.15) & (master['vol_trend'] > 1.2)]\n",
    "print(f\"  +15% on DECLINING volume (exhaustion): n={len(exhaustion)}, next 5d {exhaustion['fwd_5d'].mean()*100:+.2f}%\")\n",
    "print(f\"  +15% on INCREASING volume (confirmed): n={len(confirmed)}, next 5d {confirmed['fwd_5d'].mean()*100:+.2f}%\")\n",
    "\n",
    "# PATTERN 4: Distance from SMA\n",
    "print(\"\\nğŸ“Š PATTERN 4: Extreme Extension from 20 SMA\")\n",
    "print(\"-\"*70)\n",
    "very_extended = master[master['dist_from_sma20'] > 0.20]\n",
    "very_oversold = master[master['dist_from_sma20'] < -0.20]\n",
    "print(f\"  20%+ ABOVE SMA20 (extended): n={len(very_extended)}, next 5d {very_extended['fwd_5d'].mean()*100:+.2f}%\")\n",
    "print(f\"  20%+ BELOW SMA20 (oversold): n={len(very_oversold)}, next 5d {very_oversold['fwd_5d'].mean()*100:+.2f}%\")\n",
    "\n",
    "# PATTERN 5: Monday following a big week\n",
    "print(\"\\nğŸ“Š PATTERN 5: What happens on Monday after big weeks?\")\n",
    "print(\"-\"*70)\n",
    "# This is a proxy - Monday after 5d was up big\n",
    "big_week_then_monday = master[(master['ret_5d_past'].shift(1) > 0.10) & master['is_monday']]\n",
    "print(f\"  Monday after +10% week: n={len(big_week_then_monday)}\")\n",
    "if len(big_week_then_monday) > 5:\n",
    "    print(f\"    Monday return: {big_week_then_monday['daily_ret'].mean()*100:+.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ HIDDEN PATTERN INSIGHTS - What humans miss:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸº TEST 11: REVERSE ENGINEER SPECIFIC WINNERS (MU, APLD, OKLO)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ”¬ TEST 11: REVERSE ENGINEERING MU, APLD, OKLO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def reverse_engineer_winner(ticker):\n",
    "    \"\"\"Look at what the stock looked like before its big moves\"\"\"\n",
    "    df = master[master['ticker'] == ticker].copy()\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(f\"  {ticker}: No data\")\n",
    "        return\n",
    "    \n",
    "    # Find all +10% days\n",
    "    big_days = df[df['daily_ret'] > 0.10]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š {ticker} - Found {len(big_days)} days with +10%+ moves:\")\n",
    "    \n",
    "    for idx, row in big_days.iterrows():\n",
    "        # Get the day before\n",
    "        loc = df.index.get_loc(idx)\n",
    "        if loc > 0:\n",
    "            prev = df.iloc[loc-1]\n",
    "            print(f\"\\n  ğŸ“… {idx.date()}: +{row['daily_ret']*100:.1f}%\")\n",
    "            print(f\"     RSI day before:    {prev['rsi']:.1f}\")\n",
    "            print(f\"     Volume ratio:      {row['vol_ratio']:.2f}x\")\n",
    "            print(f\"     From 20d high:     {prev['dist_from_20d_high']*100:.1f}%\")\n",
    "            print(f\"     Past 5d momentum:  {prev['ret_5d_past']*100:+.1f}%\")\n",
    "\n",
    "for ticker in ['MU', 'APLD', 'OKLO', 'AEVA', 'VST']:\n",
    "    if ticker in master['ticker'].values:\n",
    "        reverse_engineer_winner(ticker)\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  {ticker}: Not in dataset\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ’¡ Use these profiles to identify SIMILAR setups in other stocks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808277e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ§  TRADING WISDOM TO TEST\n",
    "\n",
    "## The \"Known Truths\" That Need Proof\n",
    "\n",
    "Everything below is stuff that traders say, books teach, or seems logical.\n",
    "**But does it actually work on OUR stocks in the LAST 3 months?**\n",
    "\n",
    "We're not taking anyone's word for it. We test EVERYTHING.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š CATEGORY 1: Technical Indicator \"Rules\"\n",
    "\n",
    "### RSI (Relative Strength Index)\n",
    "**What they say:**\n",
    "- RSI < 30 = oversold = buy opportunity\n",
    "- RSI > 70 = overbought = sell/short opportunity\n",
    "- RSI divergence (price makes new low, RSI doesn't) = reversal coming\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe RSI < 30 works on big caps but fails on volatile small caps?\n",
    "- Maybe RSI < 20 is the real signal (more extreme)?\n",
    "- Maybe RSI > 70 doesn't mean sell on momentum stocks - they stay overbought for weeks?\n",
    "- Maybe RSI works better when COMBINED with volume confirmation?\n",
    "- Maybe RSI crossing back ABOVE 30 (not just being below) is the real signal?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Standard RSI < 30\n",
    "# RSI < 25 vs < 30 vs < 35\n",
    "# RSI crossing UP through 30 vs just being below 30\n",
    "# RSI < 30 + volume spike\n",
    "# RSI < 30 + sector green\n",
    "# RSI divergence detection\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Moving Averages\n",
    "**What they say:**\n",
    "- Price above 50 MA = bullish\n",
    "- Price below 50 MA = bearish\n",
    "- Golden cross (50 crosses above 200) = major bull signal\n",
    "- Death cross (50 crosses below 200) = major bear signal\n",
    "- 20 MA is \"fast\" trend, 50 is \"medium\", 200 is \"slow\"\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe MAs are too slow for volatile stocks that move 10% in a day?\n",
    "- Maybe the 10 or 8 period MA is more relevant for our fast movers?\n",
    "- Maybe distance FROM the MA matters more (extended above = pullback coming)?\n",
    "- Maybe MA works as support on pullbacks but not as signal to buy?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Price 10%+ above 20 MA = mean revert down?\n",
    "# Price touches 20 MA from above = bounce?\n",
    "# Golden/death cross on our stocks - lagging indicator?\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Volume\n",
    "**What they say:**\n",
    "- Volume confirms price movement\n",
    "- Breakout on high volume = real, breakout on low volume = fake\n",
    "- Climax volume (huge spike) = exhaustion, reversal coming\n",
    "- Accumulation = up days on higher volume than down days\n",
    "- Distribution = down days on higher volume than up days\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe 2x volume isn't enough - need 3x or 5x for signal?\n",
    "- Maybe volume spike UP day vs DOWN day mean completely different things?\n",
    "- Maybe declining volume on an uptrend is actually fine (path of least resistance)?\n",
    "- Maybe the first high volume day after quiet period is the signal (accumulation complete)?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Volume 2x vs 3x vs 5x average - which matters?\n",
    "# High volume UP day - continuation or exhaustion?\n",
    "# High volume DOWN day - capitulation (buy) or breakdown (sell)?\n",
    "# Volume trend (5 days increasing vs decreasing)\n",
    "# Volume on breakout to new highs\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Support/Resistance\n",
    "**What they say:**\n",
    "- Previous highs become resistance\n",
    "- Previous lows become support\n",
    "- Round numbers ($10, $50, $100) act as psychological levels\n",
    "- Once support breaks, it becomes resistance (and vice versa)\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe S/R doesn't work on volatile stocks that gap through levels?\n",
    "- Maybe only RECENT S/R matters (last 20 days vs 52 weeks)?\n",
    "- Maybe S/R works for entries but not exits on momentum stocks?\n",
    "- Maybe we should BUY breakouts above resistance instead of fading them?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Price near 52-week high - continuation or resistance?\n",
    "# Price near 52-week low - support or breakdown?\n",
    "# Round number analysis ($5, $10, $20 levels)\n",
    "# Previous day high/low as intraday S/R\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š CATEGORY 2: Chart Patterns\n",
    "\n",
    "### Gap Behavior\n",
    "**What they say:**\n",
    "- \"Gaps get filled\" - gaps eventually return to pre-gap price\n",
    "- Gap up = profit taking, fade it\n",
    "- Gap down = panic, buy the dip\n",
    "- \"Gap and go\" = if gap holds first 30 min, trend continues\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe gap ups in momentum stocks DON'T fill - they keep running?\n",
    "- Maybe small gaps (2-3%) fade but large gaps (10%+) continue?\n",
    "- Maybe gap direction matters less than VOLUME on the gap?\n",
    "- Maybe gaps on news are different than gaps on no news?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Gap up 5%+ - does it fade same day?\n",
    "# Gap down 5%+ - does it bounce same day?\n",
    "# Gap size vs fill probability\n",
    "# Gap + volume analysis\n",
    "# Gap on Monday vs other days\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Candlestick Patterns\n",
    "**What they say:**\n",
    "- Doji = indecision, reversal coming\n",
    "- Hammer at bottom = bullish reversal\n",
    "- Shooting star at top = bearish reversal\n",
    "- Engulfing patterns = strong reversal signal\n",
    "- Three white soldiers / three black crows = trend continuation\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe candlestick patterns are noise on daily charts for volatile stocks?\n",
    "- Maybe only LARGE candles matter (not small indecision)?\n",
    "- Maybe patterns work on higher timeframes (weekly) not daily?\n",
    "- Maybe patterns need volume confirmation to be valid?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Large red candle (>5% down) - bounce or continuation?\n",
    "# Large green candle (>5% up) - continuation or exhaustion?\n",
    "# Candle size vs next day direction\n",
    "# Body vs wick ratio meaning\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š CATEGORY 3: Momentum & Mean Reversion\n",
    "\n",
    "### Momentum\n",
    "**What they say:**\n",
    "- \"Trend is your friend\" - ride winners\n",
    "- Momentum persists - winners keep winning short term\n",
    "- \"Let winners run, cut losers fast\"\n",
    "- Relative strength (vs market) predicts future performance\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe momentum works for 3-5 days then exhausts?\n",
    "- Maybe there's a \"sweet spot\" - not too hot, not too cold?\n",
    "- Maybe momentum in our volatile stocks is shorter than blue chips?\n",
    "- Maybe momentum ONLY works with volume confirmation?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Stock up 10% last 5 days - next 5 days?\n",
    "# Stock up 20% last 5 days - continuation or reversal?\n",
    "# Momentum + RSI not overbought = better?\n",
    "# Sector momentum vs individual momentum\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Mean Reversion\n",
    "**What they say:**\n",
    "- \"What goes up must come down\"\n",
    "- Extended moves revert to the mean\n",
    "- 2 standard deviations from average = extreme, will revert\n",
    "- Rubber band effect - stretched too far, snaps back\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe mean reversion works on range-bound stocks but not trending?\n",
    "- Maybe our stocks trend more than they mean-revert?\n",
    "- Maybe you need BOTH extension AND exhaustion signal?\n",
    "- Maybe mean reversion is a losing strategy in bull markets?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Stock 2+ std devs above 20 MA - revert?\n",
    "# Stock 30%+ above 20-day average price - pullback coming?\n",
    "# Distance from recent high vs future returns\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š CATEGORY 4: Time-Based Patterns\n",
    "\n",
    "### Day of Week\n",
    "**What they say:**\n",
    "- \"Sell on Monday\" - weekend worry leads to selling\n",
    "- \"Tuesday reversal\" - Monday sellers exhausted\n",
    "- \"Friday profit taking\" - don't hold into weekend\n",
    "- \"Turnaround Tuesday\" - most common reversal day\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe day of week effects existed but are arbitraged away?\n",
    "- Maybe they only work on certain stock types?\n",
    "- Maybe our stocks have OPPOSITE patterns (Monday morning buy)?\n",
    "- Maybe it's hour of day that matters more than day of week?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Average return by day of week\n",
    "# Volatility by day of week\n",
    "# Best day to BUY vs best day to SELL\n",
    "# Monday open vs Friday close\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Time of Day (Intraday)\n",
    "**What they say:**\n",
    "- First 30 min = \"amateur hour\" - volatile, reversals common\n",
    "- 10am reversal - early trend often reverses around 10am\n",
    "- Lunch hour = low volume, choppy, avoid trading\n",
    "- Power hour (3-4pm) = real moves, institutional activity\n",
    "- Last 10 min = positioning for next day\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe the \"amateur hour\" is where we SHOULD buy (volatility = opportunity)?\n",
    "- Maybe power hour is too late - smart money moved already?\n",
    "- Maybe our small caps have different intraday patterns than SPY?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# First 30 min direction vs rest of day\n",
    "# Buying at open vs buying at 10am\n",
    "# Power hour volume vs morning volume\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Seasonal/Calendar\n",
    "**What they say:**\n",
    "- \"Sell in May, go away\" - summer months underperform\n",
    "- January effect - small caps outperform in January\n",
    "- Santa rally - end of year bullish\n",
    "- Options expiration week = volatility\n",
    "- Earnings season = increased volatility\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe these effects are too slow for our trading style?\n",
    "- Maybe knowing earnings dates matters more than season?\n",
    "- Maybe we should trade MORE during high volatility periods, not less?\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š CATEGORY 5: Sentiment & Psychology\n",
    "\n",
    "### Fear/Greed\n",
    "**What they say:**\n",
    "- \"Be fearful when others are greedy, greedy when others are fearful\"\n",
    "- VIX spike = buy opportunity (fear extreme)\n",
    "- Everyone bullish = contrarian sell signal\n",
    "- Capitulation (panic selling) = bottom near\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe VIX doesn't affect small caps directly?\n",
    "- Maybe our stocks have their own \"mini VIX\" (sector fear)?\n",
    "- Maybe capitulation volume is hard to identify in real-time?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# VIX spike days - our stocks next 5 days?\n",
    "# Market down 2%+ - our stocks bounce more/less than SPY?\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### News/Catalysts\n",
    "**What they say:**\n",
    "- \"Buy the rumor, sell the news\"\n",
    "- Good earnings = stock goes up\n",
    "- Bad earnings = stock goes down\n",
    "- Analyst upgrades/downgrades move stocks\n",
    "- Insider buying = bullish signal\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe \"sell the news\" is wrong for small caps with real catalysts?\n",
    "- Maybe good earnings are already priced in (expectation matters)?\n",
    "- Maybe insider buying is lagging (they buy months before)?\n",
    "- Maybe analyst coverage is too sparse for small caps?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Price action 5 days before vs 5 days after 8-K filings\n",
    "# Earnings date analysis (run-up, reaction, post-earnings drift)\n",
    "# Form 4 cluster detection (multiple insiders buying)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š CATEGORY 6: Sector & Correlation\n",
    "\n",
    "### Sector Behavior\n",
    "**What they say:**\n",
    "- \"A rising tide lifts all boats\" - sector moves together\n",
    "- Leaders lead, laggards lag then catch up\n",
    "- Sector rotation - money flows from one sector to another\n",
    "- When SPY tanks, correlations go to 1 (everything sells)\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe our sectors (AI, defense, quantum) are too niche for normal rules?\n",
    "- Maybe one stock CAN move while sector is flat (individual catalysts)?\n",
    "- Maybe laggards STAY laggards (don't catch up)?\n",
    "- Maybe sector ETF direction predicts individual stock direction?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# AEVA +20% - what happens to OUST, INVZ next day?\n",
    "# Sector average return vs individual stock forward return\n",
    "# Leader identification - who moves first?\n",
    "# Beta to SPY by ticker\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Correlation Breakdown\n",
    "**What they say:**\n",
    "- Diversification reduces risk\n",
    "- Uncorrelated assets protect portfolio\n",
    "- During crisis, correlations spike (no hiding place)\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe our stocks are SO correlated that diversification is illusion?\n",
    "- Maybe we should embrace correlation - go all-in on best sector?\n",
    "- Maybe negative correlation exists within our universe (AI vs defense)?\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š CATEGORY 7: Position Sizing & Risk\n",
    "\n",
    "### Position Sizing Rules\n",
    "**What they say:**\n",
    "- Never risk more than 1-2% of portfolio per trade\n",
    "- Scale into positions (don't buy all at once)\n",
    "- Add to winners, not losers (pyramiding)\n",
    "- Equal weight vs conviction weighting\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe 1-2% is too conservative for small accounts?\n",
    "- Maybe conviction weighting beats equal weight?\n",
    "- Maybe scaling in misses the move on volatile stocks?\n",
    "- Maybe adding to losers (averaging down) works if thesis intact?\n",
    "\n",
    "---\n",
    "\n",
    "### Stop Losses\n",
    "**What they say:**\n",
    "- Always use stop losses\n",
    "- 5-10% stop for volatile stocks\n",
    "- Trailing stops to lock in profits\n",
    "- Stop at support level, not arbitrary %\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe stops get hunted on volatile stocks (stop runs)?\n",
    "- Maybe mental stops better than hard stops?\n",
    "- Maybe wider stops (15-20%) make sense for our stocks?\n",
    "- Maybe time-based stops (sell after X days regardless)?\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š CATEGORY 8: Market Regime\n",
    "\n",
    "### Bull vs Bear Market\n",
    "**What they say:**\n",
    "- \"Don't fight the fed\" - monetary policy drives markets\n",
    "- Bull markets climb a wall of worry\n",
    "- Bear markets have sharp rallies that fail\n",
    "- Different strategies for different regimes\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe our growth stocks do better when rates are expected to fall?\n",
    "- Maybe small caps lead into bull markets and lag into bear?\n",
    "- Maybe we need regime detection before applying signals?\n",
    "\n",
    "---\n",
    "\n",
    "### Volatility Regime\n",
    "**What they say:**\n",
    "- Low vol begets high vol (calm before storm)\n",
    "- High vol = opportunity for active traders\n",
    "- Volatility clusters - volatile days cluster together\n",
    "- Mean reversion works better in high vol regimes\n",
    "\n",
    "**The maybes:**\n",
    "- Maybe our stocks are ALWAYS high vol, so regime doesn't matter?\n",
    "- Maybe we should size positions based on recent volatility?\n",
    "- Maybe some signals only work in certain vol environments?\n",
    "\n",
    "**Test ideas:**\n",
    "```python\n",
    "# Define high/low vol regime (rolling 20-day std)\n",
    "# Test all signals within each regime\n",
    "# Signals that work in high vol vs low vol\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸº THE \"CRAZY IDEAS\" TO TEST\n",
    "\n",
    "These might be wrong. But what if they're right?\n",
    "\n",
    "1. **Inverse RSI** - What if RSI > 70 is actually BUY on momentum stocks?\n",
    "2. **Volume Exhaustion** - What if massive volume (5x) means move is DONE?\n",
    "3. **Gap Continuation** - What if large gaps (10%+) should be CHASED not faded?\n",
    "4. **Sympathy Lag** - What if buying the 2nd mover in sector beats buying the leader?\n",
    "5. **Breakdown Buy** - What if buying NEW 52-week lows is better than buying pullbacks?\n",
    "6. **News Fade Inverse** - What if good news on small caps should be BOUGHT not sold?\n",
    "7. **Options Flow** - What if unusual options activity predicts next day direction?\n",
    "8. **Short Interest** - What if high short interest (>20%) means squeeze potential?\n",
    "9. **Insider Clusters** - What if 3+ insiders buying same week is the real signal?\n",
    "10. **SEC Filing Lag** - What if market takes 24-48 hours to digest 8-K filings?\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š THE RESEARCH MATRIX\n",
    "\n",
    "For EACH hypothesis, we need to answer:\n",
    "\n",
    "| Question | How We Measure |\n",
    "|----------|---------------|\n",
    "| Does it work? | Win rate > 50%, avg return > 0 |\n",
    "| Is it BETTER than random? | Compare to baseline (any random day) |\n",
    "| How MUCH better? | Excess return over baseline |\n",
    "| Is sample size enough? | n > 30 events ideally |\n",
    "| Does it work on ALL tickers? | Test by ticker |\n",
    "| Does it work RECENTLY? | Last 1 month vs last 3 months |\n",
    "| What makes it work BETTER? | Combinations with other signals |\n",
    "| What makes it FAIL? | Identify false signal conditions |\n",
    "\n",
    "---\n",
    "\n",
    "## â° WHY 3 MONTHS IS RIGHT\n",
    "\n",
    "For our stocks (volatile small caps), 3 months is:\n",
    "\n",
    "âœ… **Recent enough** - Market regime hasn't changed dramatically\n",
    "âœ… **Long enough** - Get ~65 trading days of data\n",
    "âœ… **Relevant data** - These stocks change fast, old data is noise\n",
    "âœ… **Multiple cycles** - Capture rallies AND pullbacks\n",
    "\n",
    "**NOT 1 month:** Too few data points, might be in unusual period\n",
    "**NOT 6 months:** Might include regime change, old patterns\n",
    "**NOT 1 year:** These stocks evolve fast, year-old data is irrelevant\n",
    "\n",
    "For our universe of 50 tickers Ã— 65 days = ~3,250 data points\n",
    "That's enough to find real patterns IF they exist.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ THE GOAL\n",
    "\n",
    "After testing all of this, we should have:\n",
    "\n",
    "1. **VALIDATED EDGES** - Signals that actually work (>60% win rate or positive expectancy)\n",
    "2. **KILLED ASSUMPTIONS** - \"Rules\" that don't work on our stocks\n",
    "3. **CONDITIONAL EDGES** - Signals that work only in certain conditions\n",
    "4. **COMBINED SIGNALS** - Stacking that improves results\n",
    "5. **TICKER-SPECIFIC** - Which stocks respond to which signals\n",
    "\n",
    "Then we build tools around PROVEN edges only.\n",
    "\n",
    "No more \"RSI said buy so I bought\" without knowing if RSI actually works on that stock.\n",
    "\n",
    "---\n",
    "\n",
    "ğŸº **This is the knowledge base. Now we test it ALL.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
